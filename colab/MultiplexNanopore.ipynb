{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr9TnWBsGLtq"
      },
      "source": [
        "# INSTRUCTIONS\n",
        "\n",
        "### **Overview**\n",
        "\n",
        "This notebook aims to help you to verify the sequence of the plasmid you've cloned with low cost.\\\n",
        "By sequencing a mixture of multiple plasmids at once by Nanopore and disassembling the obtained data, plasmid sequencing can be performed at a fraction to a tenth of the cost.\n",
        "\n",
        "The notebook consists of 3 sections. You can start the analysis at the beginning of any section below.\n",
        "\n",
        "- Pre-survey (Step 0)\n",
        "- Alignment & Calculation of consensus (Step 1-5)\n",
        "- Visualization of results (Step 6)\n",
        "\n",
        "### **Quick start**\n",
        "\n",
        "**Before you submit your samples**\n",
        "\n",
        "<details><summary>Pre-survey (Step 0)</summary><div>\n",
        "\n",
        "1. Upload your plasmid sequences (`*.fasta` or `*.dna`) under the `sample_data` directory.\n",
        "2. Select the cell \"**0. Pre-survey**\", then press \"`Runtime` -> `Run the focused cell`\".\n",
        "3. Recommended combiination of plasmids that is safe to mix will be displayed.\n",
        "\n",
        "</div></details>\n",
        "\n",
        "**Submit your samples**\n",
        "\n",
        "<details><summary>Details</summary><div>\n",
        "\n",
        "1. Verify that your plasmid is built properly by using diagnostic restriction digestion or a method with an equivalent degree of confidence.\n",
        "2. Mix plasmids according to the results of the grouping of the pre-survey. The concentration (not the molar ratios) of each plasmid should be the same.\n",
        "   \n",
        "   <table>\n",
        "      <caption>e.g. Making mixture of 3 plasmids (final 20 uL, 30 ng/uL)</caption>\n",
        "      <tr>\n",
        "        <th>\n",
        "        </th>\n",
        "        <th>\n",
        "          conc. [ng/uL]\n",
        "        </th>\n",
        "        <th>\n",
        "          volume [uL]\n",
        "        </th>\n",
        "      </tr>\n",
        "      <tr align=\"center\">\n",
        "        <td>\n",
        "          Plasmid 1\n",
        "        </td>\n",
        "        <td>\n",
        "          A\n",
        "        </td>\n",
        "        <td>\n",
        "          200 (= 20 * 30 / #_of_plasmids) / A\n",
        "        </td>\n",
        "      </tr>\n",
        "      <tr align=\"center\">\n",
        "        <td>\n",
        "          Plasmid 2\n",
        "        </td>\n",
        "        <td>\n",
        "          B\n",
        "        </td>\n",
        "        <td>\n",
        "          200 / B\n",
        "        </td>\n",
        "      </tr>\n",
        "      <tr align=\"center\">\n",
        "        <td>\n",
        "          Plasmid 3\n",
        "        </td>\n",
        "        <td>\n",
        "          C\n",
        "        </td>\n",
        "        <td>\n",
        "          200 / C\n",
        "        </td>\n",
        "      </tr>\n",
        "      <tr align=\"center\">\n",
        "        <td>\n",
        "          H2O\n",
        "        </td>\n",
        "        <td>\n",
        "          –\n",
        "        </td>\n",
        "        <td>\n",
        "          20 – (200 / A – 200 / B – 200 / C)\n",
        "        </td>\n",
        "      </tr>\n",
        "   </table>\n",
        "\n",
        "3. Send your samples to Nanopore sequencing. Be sure to receive `*.fastq` files as results. Consensus sequence results that company usually returns do not make any sense because you are sending a mixture of plasmids.\n",
        "\n",
        "</div></details>\n",
        "\n",
        "**After you get Nanopore results**\n",
        "\n",
        "<details><summary>Alignment & Calculation of consensus (Step 1-5)\n",
        "</summary><div>\n",
        "\n",
        "1. Upload your plasmid sequences (`*.fasta` or `*.dna`) and Nanopore sequencing results (`*.fastq`) under the `sample_data` directory.\n",
        "2. Select the cell \"**1. Upload and select files**\", then press \"`Runtime` -> `Run after`\".\n",
        "3. The currently running cell is indicated by a circle with a stop sign next to it.\n",
        "4. After the completion of all processes, a `result.zip` file will appear. Right-click and select \"Download\".\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>Visualization of results (Step 6)</summary><div>\n",
        "\n",
        "1. Upload a result file (`*.alignment_with_prior.txt` or `*.alignment_without_prior.txt`) under the `sample_data` directory.\n",
        "2. Enter parameters in the cell \"**6. Visualize results**\" (`target_file_path`, `target_position`, and `display_range`).\n",
        "3. Press \"`Runtime` -> `Run the focused cell`\".\n",
        "\n",
        "</div></details>\n",
        "\n",
        "### **Details**\n",
        "<details><summary>0. Pre-survey</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "# 0-0. Overview\n",
        "\n",
        "Before you submit your samples, run this cell to know what combination of plasmids is safe to mix.\\\n",
        "If you just want to analyze the nanopore-sequencing results, start from `1. Uploadand select files` cell.\n",
        "\n",
        "# 0-1. Upload reference (plasmid) sequence files.\n",
        "\n",
        "Click on the little folder icon to the left, then drag and drop files under the `sample_data` directory.\n",
        "\n",
        "Currently supported files are: \n",
        "- `*.dna` (SnapGene file)\n",
        "- `*.fasta` (FASTA file)\n",
        "\n",
        "# 0-2. Advanced settings\n",
        "\n",
        "## Parameters used for alignment\n",
        "\n",
        "- `gap_open_penalty`\n",
        "- `gap_extend_penalty`\n",
        "- `match_score`\n",
        "- `mismatch_score`\n",
        "\n",
        "Ref 1: [parasail-python](https://github.com/jeffdaily/parasail-python)\\\n",
        "Ref 2: [Daily, Jeff. (2016). Parasail: SIMD C library for global, semi-global, and local pairwise sequence alignments. BMC Bioinformatics, 17(1), 1-11.](http://dx.doi.org/10.1186/s12859-016-0930-z)\\\n",
        "Ref 2: [Smith-Waterman algorithm](https://doi.org/10.1016/0022-2836(81)90087-5)\n",
        "\n",
        "## Parameters used for classification\n",
        "- `score_threshold`\n",
        "\n",
        "The \"score\" in `score_threshold` refers to the alignment score calculated using the above four parameters, but with normalization.\n",
        "Normalization is performed by dividing the score by the length of the reference (plasmid) sequence.\n",
        "\n",
        "# 0-3. Hit `Runtime` -> `Run the focused cell`\n",
        "- The normalized alignment score and the recommended combination of plasmids will be displayed.\n",
        "- The results are also exported as `recommended_group_(# of group).svg` under the `sample_data` directory.\n",
        "- Lower alignment score between two sequence indicate that they can be mixed more safely.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>1. Upload and select files</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "# 1-1. Upload files\n",
        "\n",
        "Click on the little folder icon to the left, then drag and drop files under the `sample_data` directory to upload  your reference (plasmid) sequences and Nanopore sequencing results.\n",
        "\n",
        "- Reference sequence files can be the same files as you uploaded in the **0. Pre-survey** step.\n",
        "- Multiple `*.fastq` files can be uploaded. They will be combined inside the program.\n",
        "- Reads inside `*.fastq` files will be aligned to each reference sequence at **2. Execute alignment** step, and will be assigned to one of them at **4. Calculate consensus** step based on the threshold set at **3. Set threshold for assignment** step.\n",
        "\n",
        "Currently supported reference sequence files:\n",
        "- `*.dna` (SnapGene file)\n",
        "- `*.fasta` (FASTA file)\n",
        "\n",
        "Nanopore sequencing results:\n",
        "- `*.fastq` files (nanopore sequence results)\n",
        "\n",
        "# 1-2. Select this cell and hit `Runtime` -> `Run after`\n",
        "\n",
        "If you do not want to use all files you uploaded, press `Runtime` -> `Run the focused cell` to select files. Follow these steps:\n",
        "\n",
        "1. After you run this cell, checkboxes for selection will appear below the cell.\n",
        "2. Select files you want to include.\n",
        "3. At least 1 `*.fastq` file and 1 reference sequence files (`*.dna` or `*.fasta`) are required for the analysis.\n",
        "4. Select \"**2. Execute alignment**\" cell and hit `Runtime` -> `Run after` to process all cells after.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>2. Execute alignment</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "- If the `save_to_google_drive` option was selected, the result zip file will be uploaded to your Google Drive.\n",
        "- The meaning of the parameters are the same as those used in **0. Pre-survey** cell.\n",
        "- If the parameters set in **0. Pre-survey** cell and in this cell are different, the former will be ignored.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>3. Set threshold for assignment</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "- The meaning of the parameter is the same as that used in **0. Pre-survey** cell.\n",
        "- If the parameter set in **0. Pre-survey** cell and in this cell are different, the former will be ignored.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>4. Calculate consensus</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "Prior information on how often errors occur during the construction of plasmid, such as PCR, ligation, and assembly processes etc.\n",
        "\n",
        "- `error_rate`\\\n",
        "   e.g. A -> T, C, G, - (They are treated equally)\n",
        "\n",
        "- `ins_rate`\\\n",
        "   e.g. AA -> ANA (N represents one of the ATCG)\n",
        "\n",
        "Regardless of the settings of the above parameters, the results without taking prior information into account are also generated (i.e., `error_rate`=0.8 and `ins_rate`=0.2).\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>5. Export results</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "- After the completion of all processes, a result.zip file will appear. Right-click and select \"Download\".\n",
        "- If the `save_to_google_drive` option was selected, the result zip file will be uploaded to your Google Drive.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>6. Visualize results</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "To execute this cell, follow what is described in **Quick start**\n",
        "\n",
        "- `target_file_path`\\\n",
        "   exported alignment result file\\\n",
        "   e.g. `result/your_plasmid_file_name.alignment_without_prior.txt` ()\n",
        "   e.g. `your_plasmid_file_name.alignment_without_prior.txt` (if it is directly uploaded under the `sample_data` folder)\n",
        "\n",
        "- `target_position`\\\n",
        "   position from 5' end on the reference sequence\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>\n",
        "\n",
        "<details><summary>Known issues</summary><div>\n",
        "\n",
        "---\n",
        "\n",
        "# `results.zip` file cannot be uploaded on GoogleDrive\n",
        "\n",
        "## Feb. 01, 2023\n",
        "\n",
        "### symptom(s)\n",
        "\n",
        "Attempting to upload large files from Colaboratory to Google Drive using PyDrive fails with a `RedirectMissingLocation` exception.\n",
        "\n",
        "### cause(s)\n",
        "\n",
        "The cause appears to be a bug in httplib2, on which PyDrive depends.\n",
        "See the following issue for details.\\\n",
        "[httplib2 v0.16.0 breaks the library · Issue #803 · googleapis/google-api-python-client · GitHub](https://github.com/googleapis/google-api-python-client/issues/803)\n",
        "\n",
        "### workaround\n",
        "\n",
        "1. Execute this notebook normally from **1. Upload and select files**.\n",
        "2. When **2. Execute alignment** is executed and the access to google drive is permitted, the following warning will appear:\n",
        "   ```\n",
        "   WARNING: The following packages were previously imported in this runtime:\n",
        "     [httplib2]\n",
        "   You must restart the runtime in order to use newly installed versions.\n",
        "   ```\n",
        "3. Click `RESTART RUNTIME` button just below the warning or hit `Runtime` -> `Restart runtime`\n",
        "4. Execute this notebook normally from **1. Upload and select files** again.\n",
        "\n",
        "---\n",
        "\n",
        "</div></details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "BIoJ9pTSGCdX"
      },
      "outputs": [],
      "source": [
        "#@title # 0. Pre-survey\n",
        "#@markdown ## 0-1. Upload reference (plasmid) sequence files.\n",
        "#@markdown - `*.dna` (SnapGene file) or `*.fasta` (FASTA file)\n",
        "\n",
        "#@markdown ## 0-2. Advanced settings\n",
        "gap_open_penalty = 3   #@param {type:\"integer\"}\n",
        "gap_extend_penalty = 1 #@param {type:\"integer\"}\n",
        "match_score = 1        #@param {type:\"integer\"}\n",
        "mismatch_score = -2    #@param {type:\"integer\"}\n",
        "score_threshold = 0.96  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ## 0-3. Hit `Runtime` -> `Run the focused cell`\n",
        "\n",
        "# install dependencies\n",
        "print(\"installing dependencies...\")\n",
        "import sys, os\n",
        "# save_stdout =  sys.stdout\n",
        "# sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "!apt-get install libcairo2-dev libjpeg-dev libgif-dev\n",
        "!pip install snapgene-reader\n",
        "!pip install parasail\n",
        "!pip install pycairo\n",
        "\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.spatial.distance as distance\n",
        "import numpy as np\n",
        "import itertools\n",
        "import gc\n",
        "import parasail\n",
        "import xml.etree.ElementTree as ET\n",
        "import cairo\n",
        "from pathlib import Path\n",
        "from snapgene_reader import snapgene_file_to_dict, snapgene_file_to_seqrecord\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# sys.stdout.close()\n",
        "# sys.stdout = save_stdout\n",
        "print(\"installation: DONE\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "my_custom_matrix =parasail.matrix_create(\"ACGT\", match_score, mismatch_score)\n",
        "\n",
        "pwd = Path('/content/sample_data/')\n",
        "uploaded_refseq_file_paths = [path for path in pwd.glob(\"*.*\") if path.suffix in (\".dna\", \".fa\", \".fasta\")]\n",
        "\n",
        "if not len(uploaded_refseq_file_paths) > 1:\n",
        "    raise Exception(\"Please upload at least 2 reference files under the 'sample_data' directory!\")\n",
        "\n",
        "# functions\n",
        "def pre_survery(refseq_list):\n",
        "    N = len(refseq_list)\n",
        "    total_N = N ** 2\n",
        "    i = 0\n",
        "    score_matrix = np.empty((N, N), dtype=float)\n",
        "    for r, my_refseq in enumerate(refseq_list):\n",
        "        for c, query in enumerate(refseq_list):\n",
        "            print(f\"\\rProcessing... {i+1}/{total_N}\", end=\"\")\n",
        "            i += 1\n",
        "            if r != c:\n",
        "                duplicated_refseq_seq = my_refseq.seq + my_refseq.seq\n",
        "                score_matrix[r, c] = calc_corrected_alignment_score(duplicated_refseq_seq, query.seq)\n",
        "            else:\n",
        "                score_matrix[r, c] = 1\n",
        "    print()\n",
        "    return score_matrix\n",
        "\n",
        "def calc_corrected_alignment_score(duplicated_refseq_seq, query_seq):\n",
        "    result = parasail.sw_trace(query_seq, duplicated_refseq_seq, gap_open_penalty, gap_extend_penalty, my_custom_matrix)\n",
        "    result = MyResult_Minimum(result)\n",
        "    gc.collect()\n",
        "    return result.score / (len(duplicated_refseq_seq) / 2)\n",
        "\n",
        "def recommended_combination(score_matrix):\n",
        "\n",
        "    distance_matrix = 1 - score_matrix\n",
        "    N = len(distance_matrix)\n",
        "    for i in range(N - 1):\n",
        "        for j in range(i + 1, N):\n",
        "            v = min(distance_matrix[i, j], distance_matrix[j, i])\n",
        "            distance_matrix[i, j] = v\n",
        "            distance_matrix[j, i] = v\n",
        "\n",
        "    # draw_heatmap_core(a, x_labels=np.arange(score_matrix.shape[1]), y_labels=np.arange(score_matrix.shape[1]))\n",
        "    # plt.show()\n",
        "\n",
        "    # clustering by sequence similarity (similar sequences will be grouped)\n",
        "    dArray = distance.squareform(distance_matrix)\n",
        "    result = linkage(dArray, method='complete')\n",
        "    # np.set_printoptions(suppress=True)\n",
        "    # print(result)\n",
        "    # distance_matrix_sorted, dendro_levels = draw_dendrogram_core(distance_matrix, result)\n",
        "    # plt.show()\n",
        "    # quit()\n",
        "\n",
        "    # organize result\n",
        "    threshold = 1 - score_threshold\n",
        "    grouping = [[i] for i in range(N)]\n",
        "    for idx1, idx2, d, number_of_sub_cluster in result:\n",
        "        if d > threshold:\n",
        "            break\n",
        "        grouping.append(grouping[int(idx1)] + grouping[int(idx2)])\n",
        "        grouping[int(idx1)] = None\n",
        "        grouping[int(idx2)] = None\n",
        "    grouping = [g for g in grouping if g is not None]\n",
        "\n",
        "    print(grouping)\n",
        "\n",
        "    # distance_matrix_sorted, dendro_levels = draw_dendrogram_core(distance_matrix, result)\n",
        "    # plt.show()\n",
        "\n",
        "    score_matrix_tmp = np.copy(score_matrix)\n",
        "    def calc_group_score(index_list):\n",
        "        combination_of_index = list(itertools.combinations(index_list, 2))\n",
        "        scores = score_matrix_tmp[tuple(zip(*combination_of_index))]\n",
        "        return scores.max() * len(scores)\n",
        "\n",
        "    # 似た配列がコンビにならないように、組み合わせを選出（グループ：似た者同士の集合、コンビ：違う者同士の集合）\n",
        "    N_combination = max(len(g) for g in grouping)\n",
        "    combination_list = [[] for i in range(N_combination)]\n",
        "    # 大きいグループから処理していく\n",
        "    for c in range(N_combination, 0, -1):\n",
        "        # 指定の長さのグループを抽出、None を追加して長さを len(combination_list) に合わせる\n",
        "        selected_groups = [g + [None for i in range(N_combination - c)] for g in grouping if len(g) == c]\n",
        "        # どのような組み合わせでコンビに追加するかを全通り書き出す\n",
        "        selected_group_permuation = [list(set(itertools.permutations(g, N_combination))) for g in selected_groups]\n",
        "        product_of_selected_group_permutation = list(itertools.product(*selected_group_permuation))\n",
        "        # スコアの平均を計算\n",
        "        average_score_list = []\n",
        "        for prod in product_of_selected_group_permutation:\n",
        "            scores = [calc_group_score(combination_list[i] + [p_sub for p_sub in p if p_sub is not None]) for i, p in enumerate(zip(*prod))]\n",
        "            if len(scores):\n",
        "                average_score_list.append(np.average(scores))\n",
        "            else:\n",
        "                average_score_list.append(np.nan)\n",
        "        selected_prod = product_of_selected_group_permutation[np.argmin(average_score_list)]\n",
        "        for i, p in enumerate(zip(*selected_prod)):\n",
        "            combination_list[i].extend([p_sub for p_sub in p if p_sub is not None])\n",
        "    print(combination_list)\n",
        "    return combination_list\n",
        "\n",
        "class MyRefSeq_Minimum():\n",
        "    def __init__(self, path: Path):\n",
        "        self.path = path\n",
        "        if self.path.suffix == \".dna\":\n",
        "            snapgene_dict = snapgene_file_to_dict(self.path.as_posix())\n",
        "            # seqrecord = snapgene_file_to_seqrecord(self.path.as_posix())\n",
        "            assert snapgene_dict[\"isDNA\"]\n",
        "            self.topology = snapgene_dict[\"dna\"][\"topology\"]\n",
        "            self.strandedness = snapgene_dict[\"dna\"][\"strandedness\"]\n",
        "            self.length = snapgene_dict[\"dna\"][\"length\"]\n",
        "            self.seq = snapgene_dict[\"seq\"]\n",
        "            if self.topology != \"circular\":\n",
        "                print(f\"WARNING: {self.path.name} is not circular!\")\n",
        "            assert self.strandedness == \"double\"\n",
        "            assert self.length == len(self.seq)\n",
        "        elif self.path.suffix in (\".fasta\", \".fa\"):\n",
        "            with open(self.path.as_posix(), 'r') as f:\n",
        "                self.seq=''\n",
        "                for line in f.readlines():\n",
        "                    if line[0] != '>':\n",
        "                        self.seq += line.strip()\n",
        "            self.topology = \"circular\"\n",
        "            self.strandedness = \"double\"\n",
        "            self.length = len(self.seq)\n",
        "        else:\n",
        "            raise Exception(f\"Unsupported type of sequence file: {self.path}\")\n",
        "    def reverse_complement(self):\n",
        "        return str(Seq(self.seq).reverse_complement())\n",
        "\n",
        "class MyResult_Minimum():\n",
        "    def __init__(self, parasail_result) -> None:\n",
        "        self.cigar = parasail_result.cigar.decode.decode(\"ascii\")\n",
        "        self.score = parasail_result.score\n",
        "        self.beg_ref = parasail_result.cigar.beg_ref\n",
        "        self.beg_query = parasail_result.cigar.beg_query\n",
        "        self.end_ref = parasail_result.end_ref\n",
        "        self.end_query = parasail_result.end_query\n",
        "\n",
        "class StringSizeWithSuffix():\n",
        "    def __init__(self, size_with_suffix):\n",
        "        if isinstance(size_with_suffix, str):\n",
        "            m = re.match(r\"([0-9.]+)([a-z]+)\", size_with_suffix)\n",
        "            self.size = float(m.group(1))\n",
        "            self.suffix = m.group(2)\n",
        "        elif isinstance(size_with_suffix, list):\n",
        "            self.size = size_with_suffix[0]\n",
        "            self.suffix = size_with_suffix[1]\n",
        "        else:\n",
        "            raise Exception(\"error!\")\n",
        "    def __add__(self, v):\n",
        "        return StringSizeWithSuffix([self.size + v, self.suffix])\n",
        "    def __sub__(self, v):\n",
        "        return StringSizeWithSuffix([self.size - v, self.suffix])\n",
        "    def __mul__(self, v):\n",
        "        return StringSizeWithSuffix([self.size * v, self.suffix])\n",
        "    def __truediv__(self, v):\n",
        "        return StringSizeWithSuffix([self.size / v, self.suffix])\n",
        "    def __floordiv__(self, v):\n",
        "        return StringSizeWithSuffix([self.size // v, self.suffix])\n",
        "    def __iadd__(self, v):\n",
        "        self.size += v\n",
        "        return self\n",
        "    def __isub__(self, v):\n",
        "        self.size -= v\n",
        "        return self\n",
        "    def __imul__(self, v):\n",
        "        self.size *= v\n",
        "        return self\n",
        "    def __itruediv__(self, v):\n",
        "        self.size /= v\n",
        "        return self\n",
        "    def __ifloordiv__(self, v):\n",
        "        self.size //= v\n",
        "        return self\n",
        "    def __str__(self):\n",
        "        return f\"{self.size}{self.suffix}\"\n",
        "\n",
        "class Svg():\n",
        "    def __init__(self, path):\n",
        "        ET.register_namespace(\"\",\"http://www.w3.org/2000/svg\")\n",
        "        tree = ET.parse(path)\n",
        "        self.svg = tree.getroot()   # svg\n",
        "    def adjust_margin(self, path, l, r, t, b):  # l, r, t, b represents margins to add to the viewbox of svg file.\n",
        "        self.svg.attrib[\"width\"] = str(StringSizeWithSuffix(self.svg.attrib[\"width\"]) + l + r)\n",
        "        self.svg.attrib[\"height\"] = str(StringSizeWithSuffix(self.svg.attrib[\"height\"]) + t + b)\n",
        "        view_box = list(map(float, self.svg.attrib[\"viewBox\"].split(\" \")))\n",
        "        view_box[0] -= l    # x0\n",
        "        view_box[1] -= t    # y0\n",
        "        view_box[2] += l + r    # x1\n",
        "        view_box[3] += t + b    # y1\n",
        "        self.svg.attrib[\"viewBox\"] = \" \".join(map(str, view_box))\n",
        "    def draw_path(self, d, stroke=\"#000000\", stroke_width=2, stroke_linecap=\"butt\", stroke_linejoin=\"miter\", stroke_opacity=1, stroke_miterlimit=4, stroke_dasharray=\"none\"):\n",
        "        self.svg.append(ET.Element(\n",
        "            'path', \n",
        "            attrib={\n",
        "                \"style\" :f\"fill:none;stroke:{stroke};stroke-width:{stroke_width};stroke-linecap:{stroke_linecap};stroke-linejoin:{stroke_linejoin};stroke-opacity:{stroke_opacity};stroke-miterlimit:{stroke_miterlimit};stroke-dasharray:{stroke_dasharray}\", \n",
        "                \"d\"     :d\n",
        "            }\n",
        "        ))\n",
        "    def draw_text(self, string, x, y, font_style=\"normal\", font_weight=\"normal\", font_size=\"30px\", line_height=1.25, font_family=\"sans-serif\", fill=\"#000000\", fill_opacity=1, stroke=\"none\", stroke_width=0.75, text_anchor=\"middle\", text_align=\"center\"):\n",
        "        text = ET.Element(\n",
        "            \"text\", \n",
        "            attrib={\n",
        "                \"xml:space\" :\"preserve\", \n",
        "                \"style\"     :f\"font-style:{font_style};font-weight:{font_weight};font-size:{font_size};line-height:{line_height};font-family:{font_family};fill:{fill};fill-opacity:{fill_opacity};stroke:{stroke};stroke-width:{stroke_width};text-anchor:{text_anchor};text-align:{text_align}\", \n",
        "                \"x\"         :str(x), \n",
        "                \"y\"         :str(y), \n",
        "            }\n",
        "        )\n",
        "        text.text = string\n",
        "        self.svg.append(text)\n",
        "    @staticmethod\n",
        "    def textsize(text, fontsize, font_style):\n",
        "        tmp_svg_path = \"undefined.svg\"\n",
        "        surface = cairo.SVGSurface(tmp_svg_path, 1280, 200)\n",
        "        cr = cairo.Context(surface)\n",
        "        cr.select_font_face(font_style, cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_BOLD)\n",
        "        cr.set_font_size(fontsize)\n",
        "        xbearing, ybearing, width, height, xadvance, yadvance = cr.text_extents(text)\n",
        "        os.remove(tmp_svg_path)\n",
        "        return {\n",
        "            \"xbearing\":xbearing, \n",
        "            \"ybearing\":ybearing, \n",
        "            \"width\":width, \n",
        "            \"height\":height, \n",
        "            \"xadvance\":xadvance, \n",
        "            \"yadvance\":yadvance\n",
        "        }\n",
        "    def save(self, path):   # 上書き保存されます\n",
        "        tree = ET.ElementTree(element=self.svg)\n",
        "        tree.write(path, encoding='utf-8', xml_declaration=True)\n",
        "\n",
        "class D(str):\n",
        "    def __new__(cls, path_command_list=[]):\n",
        "        initial_string = \" \".join([f\"{path_command} {','.join(map(str, values))}\" for path_command, values in path_command_list])\n",
        "        self = super().__new__(cls, initial_string)\n",
        "        return self\n",
        "    def append(self, path_command, values):\n",
        "        # example of horizontal line: \"M 6.7760638,-8.370432 H 169.80019\"\n",
        "        self += f\"{path_command} {','.join(map(str, values))}\"\n",
        "\n",
        "def draw_heatmap(score_matrix, refseq_names, comb_idx_list, threshold_used, save_path):\n",
        "    # label\n",
        "    comb_txt_list = [f\"threshold={threshold_used}\"] + [', '.join(['P' + str(i+1) for i in comb_idx_list])]\n",
        "    font_style = \"Helvetica\"\n",
        "    tmp_names = [f\"P{i+1}\" for i in range(len(refseq_names))]\n",
        "    details_list = [f\"{i: <4}: {j}\" for i, j in zip(tmp_names, refseq_names)] + [\"\"] + comb_txt_list\n",
        "\n",
        "    # size\n",
        "    dpi = 72\n",
        "    value_font_size=10\n",
        "    tick_font_size=12\n",
        "    label_font_size = 14\n",
        "    details_font_size = 8\n",
        "    left_top_margin = (tick_font_size + label_font_size) * 2\n",
        "    bottom_margin = details_font_size * (len(details_list) + 1)\n",
        "    details_width = max([Svg.textsize(details, details_font_size, font_style)[\"xadvance\"] for details in details_list])\n",
        "\n",
        "    # make matplotlib fig\n",
        "    fig, ax = draw_heatmap_core(score_matrix, x_labels=tmp_names, y_labels=tmp_names, value_font_size=value_font_size, tick_font_size=tick_font_size)\n",
        "\n",
        "    # highlight combination\n",
        "    for i in comb_idx_list:\n",
        "        for j in comb_idx_list:\n",
        "            if i == j:\n",
        "                continue\n",
        "            else:\n",
        "                highlight_cell(i, j, ax=ax, color=\"r\")\n",
        "\n",
        "    # add titles etc.\n",
        "    ax.set_xlabel(\"query\", fontsize=label_font_size^)\n",
        "    ax.set_ylabel(\"reference\", fontsize=label_font_size)\n",
        "    plt.savefig(save_path, dpi=dpi)\n",
        "\n",
        "    # adjust saved svg\n",
        "    svg = Svg(save_path)\n",
        "    x0, y0, x1, y1 = svg.svg.attrib[\"viewBox\"].split(\" \")\n",
        "    assert float(x0) == float(y0) == 0\n",
        "    for i, details in enumerate(details_list):\n",
        "        svg.draw_text(details, x=label_font_size - left_top_margin, y=float(y1) + float(y0) + details_font_size * (i + 1), font_size=details_font_size, text_anchor=\"left\", font_style=font_style)\n",
        "    right_margin = max(details_width + label_font_size - left_top_margin - float(x1), (tick_font_size + label_font_size) * 2)\n",
        "    svg.adjust_margin(save_path, l=left_top_margin, r=right_margin, t=left_top_margin, b=bottom_margin)\n",
        "    svg.save(save_path)\n",
        "\n",
        "def draw_heatmap_core(score_matrix, x_labels, y_labels, value_font_size=10, tick_font_size=14, subplot=[1,1,1]):\n",
        "    assert score_matrix.shape == (len(y_labels), len(x_labels))\n",
        "    figsize_unit = 0.5\n",
        "\n",
        "    fig =plt.figure(figsize=(len(x_labels) * figsize_unit, len(y_labels) * figsize_unit))\n",
        "    ax = plt.subplot(*subplot)\n",
        "    im = plt.imshow(score_matrix, cmap=\"YlGn\", vmin=0, vmax=1)\n",
        "    bar = plt.colorbar(im, fraction=0.046, pad=0.04)\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    for i in range(score_matrix.shape[0]):\n",
        "        for j in range(score_matrix.shape[1]):\n",
        "            if np.isnan(score_matrix[i, j]):\n",
        "                continue\n",
        "            value = f\"{np.round(score_matrix[i, j], 3):0<5}\"\n",
        "            if np.absolute(score_matrix[i, j]) < score_matrix.max()/2:\n",
        "                text = ax.text(j, i, value, ha=\"center\", va=\"center\", color=\"k\", fontsize=value_font_size)\n",
        "            else:\n",
        "                text = ax.text(j, i, value, ha=\"center\", va=\"center\", color=\"w\", fontsize=value_font_size)\n",
        "\n",
        "    # Show all ticks and label them with the respective list entries\n",
        "    # x\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.xaxis.set_label_position('top')\n",
        "    ax.set_xticks(np.arange(len(x_labels)))\n",
        "    ax.set_xticklabels(labels=x_labels, fontsize=tick_font_size)\n",
        "    \n",
        "    # y\n",
        "    ax.set_yticks(np.arange(len(y_labels)))\n",
        "    ax.set_yticklabels(labels=y_labels, fontsize=tick_font_size)\n",
        "    plt.subplots_adjust(bottom=0.0, left=0.0, right=1, top=1)\n",
        "    return fig, ax\n",
        "\n",
        "def highlight_cell(x, y, ax=None, **kwargs):\n",
        "    rect = plt.Rectangle((x-0.45, y-0.45), 0.9, 0.9, fill=False, **kwargs)\n",
        "    ax = ax or plt.gca()\n",
        "    ax.add_patch(rect)\n",
        "    return rect\n",
        "\n",
        "# open files\n",
        "my_refseq_list = [\n",
        "    MyRefSeq_Minimum(refseq_file_path) for refseq_file_path in uploaded_refseq_file_paths\n",
        "]\n",
        "\n",
        "# calc distance & propose optimized combination\n",
        "score_matrix = pre_survery(my_refseq_list)\n",
        "comb = recommended_combination(score_matrix)\n",
        "refseq_names = [refseq.path.name for refseq in my_refseq_list]\n",
        "\n",
        "# remove before make\n",
        "for i in pwd.glob(f\"recommended_group_*.svg\"):\n",
        "    i.unlink()\n",
        "\n",
        "# draw histogram(s)\n",
        "for group_idx, comb_idx_list in enumerate(comb):\n",
        "    save_path = pwd / (f\"recommended_group_{group_idx}.svg\")\n",
        "    draw_heatmap(score_matrix, refseq_names, comb_idx_list, score_threshold, save_path)\n",
        "\n",
        "print()\n",
        "print(\"#########################\")\n",
        "print(\"# Recommended groupings #\")\n",
        "print(\"#########################\")\n",
        "for group_idx, comb_idx_list in enumerate(comb):\n",
        "    print(f\"Group{group_idx}\")\n",
        "    for comb_idx in comb_idx_list:\n",
        "        print(f\"P{comb_idx+1: <4}: \" + refseq_names[comb_idx])\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "318776578cb448a2b5c101151734ae76",
            "eed23829fc7a456287faec5b10a12212",
            "d7be7716042443819bac1e4f59285daf",
            "ebebfcf446e8496b8b42a96671f872f6",
            "9e3a66f823f74afd86134878512f5f34",
            "55b7831a74184e468f24326445969af4",
            "57457741eb7a45b296b7b6abbed69a16",
            "0eef62aa5a6d4ec0b3f43659125403e9",
            "ea6a03d5a0254d2fa97f07f4df2c254a",
            "a99c32318f404a8db6de10bac701b989",
            "9869aa93aaf7422dac304d4b29b951d4",
            "7ebf5aabec97438ea321eaadd47b8e25",
            "7280ca6c2e804f39967ffac52e93ade5",
            "024ac7d11e9e4f1a9556f80496032998",
            "15f0c4bbf3904b8aa2ef8e060aa05935",
            "667c569a0355492285af675400e9c10f",
            "dfaa5c7dc4794e53ba588eeee451a75f",
            "ff91334172304cd5bbe2c8d24b177685",
            "9e7bf163628e45cc88a5e471f690c3e8",
            "7851a321173e404b89eb647f2da14df2",
            "b7e7c0fb2461485ba1bf0837a84d4407",
            "4b60962f9b224da687e49c5cea7e138f",
            "cf5e783359944dddb8ebc5e445d08834",
            "a530f147945346bca51675b22f78b3eb",
            "ef911121b22d4cffb15d3fe8eac422ce",
            "c3fa16b75f204a63ad0f134f3ef2b0d4",
            "f69ce397ca6845d299aeca9215f2e7b6",
            "dd421451047a4033bcda49b4708a6a78",
            "445a79881cda41018d41067aec740e1f",
            "c58b7a3df57443f1bb41a77564bf037d",
            "2f175025fe254644b18a23dec4fea689",
            "67840ff1d93c4da1a7c577cc958a13a5",
            "b3a6e323e9d64815ac29813c176d017f",
            "7fb13657e3194500be4456389f3a4a2d"
          ]
        },
        "id": "5TrFiqLrx8Mq",
        "outputId": "bb2030cb-4c20-4f17-c8d6-df811760dc64"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "318776578cb448a2b5c101151734ae76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='# fastq files'), Checkbox(value=True, description='Uematsu_n7x_1_MU-test1.fastq', …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3a6e323e9d64815ac29813c176d017f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title # 1. Upload and select files\n",
        "\n",
        "app_name = \"MyApp\"\n",
        "version = \"0.1.1\"\n",
        "description = \"written by MU\"\n",
        "\n",
        "from pathlib import Path\n",
        "pwd = Path('/content/sample_data/')\n",
        "uploaded_fastq_files = [path for path in pwd.glob(\"*.fastq\")]\n",
        "uploaded_refseq_files = [path for path in pwd.glob(\"*.*\") if path.suffix in (\".dna\", \".fa\", \".fasta\")]\n",
        "\n",
        "if not len(uploaded_fastq_files) > 0:\n",
        "    raise Exception(\"Please upload fastq files under the 'sample_data' directory!\")\n",
        "if not len(uploaded_refseq_files) > 0:\n",
        "    raise Exception(\"Please upload reference files under the 'sample_data' directory!\")\n",
        "\n",
        "#@markdown ## 1-1. Upload files\n",
        "#@markdown - `*.dna` (SnapGene file) or `*.fasta` (FASTA file)\n",
        "#@markdown - `*.fastq` (Nanopore sequence results)\n",
        "\n",
        "#@markdown ## 1-2. Select this cell and hit `Runtime` -> `Run after`\n",
        "\n",
        "from IPython.display import display\n",
        "from ipywidgets import Checkbox, VBox, Layout, interactive_output, Label\n",
        "# widgets\n",
        "child_widget_list = [Label(\"# fastq files\")]\n",
        "arg_dict = {}\n",
        "for uploaded_fastq in uploaded_fastq_files:\n",
        "    ckbx = Checkbox(value=True, description=uploaded_fastq.name, indent=False, layout=Layout(width='80%'))\n",
        "    child_widget_list.append(ckbx)\n",
        "    arg_dict[uploaded_fastq.name] = ckbx\n",
        "child_widget_list.extend([Label(\" \"), Label(\"# dna files\")])\n",
        "for uploaded_refseq in uploaded_refseq_files:\n",
        "    ckbx = Checkbox(value=True, description=uploaded_refseq.name, indent=False, layout=Layout(width='80%'))\n",
        "    child_widget_list.append(ckbx)\n",
        "    arg_dict[uploaded_refseq.name] = ckbx\n",
        "ui = VBox(children=child_widget_list)\n",
        "\n",
        "# observation function\n",
        "def select_data(**kwargs):\n",
        "    N_fastq = sum([1 for k, ckbx in kwargs.items() if (ckbx & k.endswith(\".fastq\"))])\n",
        "    N_refseq = sum([1 for k, ckbx in kwargs.items() if ckbx & (not k.endswith(\".fastq\"))])\n",
        "    if (N_fastq > 0) & (N_refseq > 0):\n",
        "        print(f\"\\n{N_fastq} fastq files selected\\n{N_refseq} reference sequence files selected\")\n",
        "    else:\n",
        "        error_text = \"\"\n",
        "        if N_fastq == 0:\n",
        "            error_text += f\"\\nPlease select at least 1 fastq file!\"\n",
        "        if N_refseq == 0:\n",
        "            error_text += f\"\\nPlease select at least 1 reference sequence file!\"\n",
        "        print(error_text)\n",
        "\n",
        "# display\n",
        "out = interactive_output(select_data, arg_dict)\n",
        "display(ui, out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "lp4ACHXs8THv",
        "outputId": "6fb05a8c-d3f1-43a1-eccd-88f7f69ffc96"
      },
      "outputs": [],
      "source": [
        "#@title # 2. Execute alignment\n",
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "if save_to_google_drive:\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "gap_open_penalty = 3   #@param {type:\"integer\"}\n",
        "gap_extend_penalty = 1 #@param {type:\"integer\"}\n",
        "match_score = 1        #@param {type:\"integer\"}\n",
        "mismatch_score = -2    #@param {type:\"integer\"}\n",
        "\n",
        "print(\"installing dependencies...\")\n",
        "import sys, os\n",
        "# save_stdout =  sys.stdout\n",
        "# sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "!pip install -U httplib2==0.15.0\n",
        "!pip install snapgene-reader\n",
        "!pip install parasail\n",
        "\n",
        "# sys.stdout.close()\n",
        "# sys.stdout = save_stdout\n",
        "\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import copy\n",
        "import zipfile\n",
        "import parasail\n",
        "import gc\n",
        "import datetime\n",
        "import textwrap\n",
        "import contextlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "from itertools import product\n",
        "from collections import OrderedDict, namedtuple, defaultdict\n",
        "from snapgene_reader import snapgene_file_to_dict, snapgene_file_to_seqrecord\n",
        "from Bio.Seq import Seq\n",
        "from numpy.core.memmap import uint8\n",
        "from PIL import Image\n",
        "\n",
        "class MyFastQ(OrderedDict):\n",
        "    def __init__(self, path=None):\n",
        "        super().__init__()\n",
        "        self.path = path\n",
        "        if self.path is not None: # for deep copy\n",
        "            with open(self.path.as_posix(), \"r\") as f:\n",
        "                fastq_txt = f.readlines()\n",
        "            # check\n",
        "            self.N_seq, mod = divmod(len(fastq_txt), 4)\n",
        "            assert mod == 0\n",
        "            # register\n",
        "            for i in range(self.N_seq):\n",
        "                seq_id = fastq_txt[4 * i].strip()\n",
        "                seq = fastq_txt[4 * i + 1].strip()\n",
        "                p = fastq_txt[4 * i + 2].strip()\n",
        "                q_scores = [ord(q) - 33 for q in fastq_txt[4 * i + 3].strip()]\n",
        "                assert p == \"+\"\n",
        "                assert len(seq) == len(q_scores)\n",
        "                self[seq_id] = [seq, q_scores]\n",
        "        else:\n",
        "            pass\n",
        "    def get_read_lengths(self):\n",
        "        return np.array([len(v[0]) for v in self.values()])\n",
        "    def get_q_scores(self):\n",
        "        q_scores = []\n",
        "        for v in self.values():\n",
        "            q_scores.extend(v[1])\n",
        "        return np.array(q_scores)\n",
        "    def get_new_seq_id(self, k):\n",
        "        if k not in self.keys():\n",
        "            return k\n",
        "        else:\n",
        "            n = 1\n",
        "            new_k = f\"{k} {n}\"\n",
        "            while new_k in self.keys():\n",
        "                n += 1\n",
        "                new_k = f\"{k} {n}\"\n",
        "            return new_k\n",
        "    def append(self, fastq):\n",
        "        for k, v in fastq.items():\n",
        "            new_k = self.get_new_seq_id(k)\n",
        "            self[new_k] = v\n",
        "    @staticmethod\n",
        "    def combine(fastq_list):\n",
        "        assert len(fastq_list) > 1\n",
        "        combined_fastq = copy.deepcopy(fastq_list[0])\n",
        "        for fastq in fastq_list[1:]:\n",
        "            combined_fastq.append(fastq)\n",
        "        return combined_fastq\n",
        "    def __getitem__(self, k):\n",
        "        if not isinstance(k, slice):\n",
        "            return OrderedDict.__getitem__(self, k)\n",
        "        x = self.__class__()\n",
        "        if k.start is None: start = 0\n",
        "        else:               start = k.start\n",
        "        if k.stop is None: stop = len(self) - k.stop\n",
        "        else:              stop = k.stop\n",
        "        assert (0 <= start <= stop)\n",
        "        for idx, key in enumerate(self.keys()):\n",
        "            if start <= idx < stop:\n",
        "                x[key] = self[key]\n",
        "        return x\n",
        "\n",
        "class MyRefSeq():\n",
        "    def __init__(self, path: Path):\n",
        "        self.path = path\n",
        "        if self.path.suffix == \".dna\":\n",
        "            snapgene_dict = snapgene_file_to_dict(self.path.as_posix())\n",
        "            # seqrecord = snapgene_file_to_seqrecord(self.path.as_posix())\n",
        "            assert snapgene_dict[\"isDNA\"]\n",
        "            self.topology = snapgene_dict[\"dna\"][\"topology\"]\n",
        "            self.strandedness = snapgene_dict[\"dna\"][\"strandedness\"]\n",
        "            self.length = snapgene_dict[\"dna\"][\"length\"]\n",
        "            self.seq = snapgene_dict[\"seq\"]\n",
        "            if self.topology != \"circular\":\n",
        "                print(f\"WARNING: {self.path.name} is not circular!\")\n",
        "            assert self.strandedness == \"double\"\n",
        "            assert self.length == len(self.seq)\n",
        "        elif self.path.suffix in (\".fasta\", \".fa\"):\n",
        "            with open(self.path.as_posix(), 'r') as f:\n",
        "                self.seq=''\n",
        "                for line in f.readlines():\n",
        "                    if line[0] != '>':\n",
        "                        self.seq += line.strip()\n",
        "            self.topology = \"circular\"\n",
        "            self.strandedness = \"double\"\n",
        "            self.length = len(self.seq)\n",
        "        else:\n",
        "            raise Exception(f\"Unsupported type of sequence file: {self.path}\")\n",
        "    def reverse_complement(self):\n",
        "        return str(Seq(self.seq).reverse_complement())\n",
        "\n",
        "# get files selected above and generate class objects\n",
        "fastq_list = []\n",
        "refseq_list = []\n",
        "for child_widget in child_widget_list:\n",
        "    if not isinstance(child_widget, Checkbox):\n",
        "        continue\n",
        "    if child_widget.value & child_widget.description.endswith(\".fastq\"):\n",
        "        fastq = MyFastQ(pwd / child_widget.description)\n",
        "        fastq_list.append(fastq)\n",
        "    elif child_widget.value & (not child_widget.description.endswith(\".fastq\")):\n",
        "        refseq = MyRefSeq(pwd / child_widget.description)\n",
        "        refseq_list.append(refseq)\n",
        "\n",
        "# assert refseq\n",
        "if len(refseq_list) == 0:\n",
        "    raise Exception(\"Please select at least 1 reference sequence file!\")\n",
        "refseq_stem_list = [refseq.path.stem for refseq in refseq_list]\n",
        "if len(refseq_stem_list) != len(set(refseq_stem_list)):\n",
        "    raise Exception(\"The file name must not be the same even if the extension is different.\")\n",
        "\n",
        "# assert fastq\n",
        "if len(fastq_list) > 1:\n",
        "    combined_fastq = MyFastQ.combine(fastq_list)\n",
        "elif len(fastq_list) == 1:\n",
        "    combined_fastq = copy.deepcopy(fastq_list[0])\n",
        "else:\n",
        "    raise Exception(\"Please select at least 1 fastq file!\")\n",
        "combined_fastq.path = [fastq.path for fastq in fastq_list]\n",
        "print(\"installation: DONE\")\n",
        "\n",
        "# Definition of main classes\n",
        "class MyResult():\n",
        "    def __init__(self, parasail_result) -> None:\n",
        "        self.cigar = parasail_result.cigar.decode.decode(\"ascii\")\n",
        "        self.score = parasail_result.score\n",
        "        self.beg_ref = parasail_result.cigar.beg_ref\n",
        "        self.beg_query = parasail_result.cigar.beg_query\n",
        "        self.end_ref = parasail_result.end_ref\n",
        "        self.end_query = parasail_result.end_query\n",
        "\n",
        "class MyAligner():\n",
        "    gap_open_penalty = gap_open_penalty\n",
        "    gap_extend_penalty = gap_extend_penalty\n",
        "    match_score = match_score\n",
        "    mismatch_score = mismatch_score\n",
        "    my_custom_matrix = my_custom_matrix =parasail.matrix_create(\"ACGT\", match_score, mismatch_score)\n",
        "    def __init__(self, refseq_list, combined_fastq):\n",
        "        self.refseq_list = refseq_list\n",
        "        self.combined_fastq = combined_fastq\n",
        "        self.duplicated_refseq_seq_list = []\n",
        "        self.is_refseq_seq_all_ATGC_list = []\n",
        "        for refseq in refseq_list:\n",
        "            self.duplicated_refseq_seq_list.append(refseq.seq + refseq.seq)\n",
        "            is_all_ATCG = all([b.upper() in \"ATCG\" for b in refseq.seq])\n",
        "            if not is_all_ATCG:\n",
        "                print(f\"\\033[38;2;255;0;0mWARNING: Non-ATCG letter(s) were found in '{refseq.path.name}'.\\nWhen calculating the alignment score, they are treated as 'mismatched', no matter what characters they are.\\033[0m\")\n",
        "            self.is_refseq_seq_all_ATGC_list.append(is_all_ATCG)\n",
        "    # refが環状プラスミドであるために、それを元に戻すのに使う（プラスミド上のどこがシーケンスの始まりと終わりなのか）を決めるのに使うカスタムのスコア\n",
        "    def get_custom_cigar_score_dict(self):\n",
        "        return {\n",
        "            \"=\":self.match_score, \n",
        "            \"X\":self.mismatch_score, \n",
        "            \"D\":self.gap_open_penalty * -1, \n",
        "            \"H\":self.gap_open_penalty * -1, \n",
        "            \"S\":0, \n",
        "            \"N\":0, \n",
        "            \"I\":0\n",
        "        }\n",
        "    # calcualted based on gap_open_penalty, gap_extend_penalty, match_score, mismatch_score\n",
        "    def clac_cigar_score(self, cigar_str):\n",
        "        # なぜか result の cigar に、左端にたくさん D もしくは I が連なることがあるので、それを除く\n",
        "        cigar_str_NL_list = re.findall('(\\d+)(\\D)', cigar_str)\n",
        "        if cigar_str_NL_list[0][1] == \"D\":\n",
        "            cigar_str_NL_list = cigar_str_NL_list[1:]\n",
        "        elif cigar_str_NL_list[0][1] == \"I\":\n",
        "            cigar_str_NL_list = cigar_str_NL_list[1:]\n",
        "        score = 0\n",
        "        for N, L in cigar_str_NL_list:\n",
        "            N = int(N)\n",
        "            if L == \"=\":\n",
        "                score += self.match_score * N\n",
        "            elif L == \"X\":\n",
        "                score += self.mismatch_score * N\n",
        "            elif L in \"DI\":\n",
        "                score -= self.gap_open_penalty + self.gap_extend_penalty * (N - 1)\n",
        "            else:\n",
        "                raise Exception(f\"unknown letter code: {L}\")\n",
        "        return score\n",
        "    def align_all(self):\n",
        "        fastq_len = len(self.combined_fastq)\n",
        "        result_dict = OrderedDict()\n",
        "        for query_idx, (seq_id, (query_seq, q_scores)) in enumerate(list(self.combined_fastq.items())):\n",
        "            print(f\"\\rExecuting alignment: {query_idx + 1} out of {fastq_len} ({seq_id})\", end=\"\")\n",
        "            # calc scores for each refseq\n",
        "            result_list = []\n",
        "            for duplicated_refseq_seq, is_refseq_seq_all_ATGC in zip(self.duplicated_refseq_seq_list, self.is_refseq_seq_all_ATGC_list):\n",
        "                # なぜか result の cigar に、左端にたくさん D もしくは I が連なることがあるが、多分スコアはちゃんと計算されてる\n",
        "                result = parasail.sw_trace(query_seq, duplicated_refseq_seq, self.gap_open_penalty, self.gap_extend_penalty, self.my_custom_matrix)\n",
        "                result = MyResult(result)\n",
        "                result_rc = parasail.sw_trace(str(Seq(query_seq).reverse_complement()), duplicated_refseq_seq, self.gap_open_penalty, self.gap_extend_penalty, self.my_custom_matrix)\n",
        "                result_rc = MyResult(result_rc)\n",
        "                # 一応スコアを確認する\n",
        "                if is_refseq_seq_all_ATGC:\n",
        "                    assert result.score == self.clac_cigar_score(result.cigar)\n",
        "                    assert result_rc.score == self.clac_cigar_score(result_rc.cigar)\n",
        "                # レジスター\n",
        "                result_list.append(result)\n",
        "                result_list.append(result_rc)\n",
        "                gc.collect()\n",
        "            result_dict[seq_id] = result_list\n",
        "        return result_dict\n",
        "\n",
        "class MyCigarStr(str):\n",
        "    def __new__(cls, cigar_str):\n",
        "        # when common cigar strings are passed\n",
        "        if cigar_str[0].isdecimal():\n",
        "            val = \"\".join([\n",
        "                L for N, L in re.findall('(\\d+)(\\D)', cigar_str)\n",
        "                    for i in range(int(N))\n",
        "            ])\n",
        "            self = super().__new__(cls, val)\n",
        "            return self\n",
        "        # when \"MyCigarStr\" strings are passed\n",
        "        else:\n",
        "            self = super().__new__(cls, cigar_str)\n",
        "            return self\n",
        "    def __iadd__(self, other):\n",
        "        return self.__class__(self + other)\n",
        "    def invert(self):\n",
        "        return self.__class__(self[::-1])\n",
        "    def number_of_letters_on_5prime(self, letters):\n",
        "        for i, l in enumerate(self):\n",
        "            if l not in letters:\n",
        "                return i\n",
        "    def number_of_letters_on_3prime(self, letters):\n",
        "        for k, l in enumerate(self[::-1]):\n",
        "            if l not in letters:\n",
        "                return k\n",
        "    def clip_from_both_ends(self, letters):\n",
        "        i = self.number_of_letters_on_5prime(letters)\n",
        "        k = self.number_of_letters_on_3prime(letters)\n",
        "        return self.__class__(self[i:len(self) - k])\n",
        "    def clipped_len(self):\n",
        "        return len(self.clip())\n",
        "\n",
        "# Execute\n",
        "my_aligner = MyAligner(refseq_list, combined_fastq)\n",
        "result_dict = my_aligner.align_all()\n",
        "print()\n",
        "print(\"alignment: DONE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "7TNn4euoS-ej",
        "outputId": "e0f72d26-9448-4777-ebd7-124254cff561"
      },
      "outputs": [],
      "source": [
        "#@title # 3. Set threshold for assignment\n",
        "\n",
        "score_threshold = 0.5  #@param {type:\"number\"}\n",
        "\n",
        "class AlignmentResult():\n",
        "    score_threshold = score_threshold\n",
        "    def __init__(self, result_dict, my_aligner):\n",
        "        self.result_dict = result_dict\n",
        "        self.my_aligner = my_aligner\n",
        "        # attributs to register results\n",
        "        self.score_list_ALL = None\n",
        "        self.result_info_assigned = None\n",
        "        self.aligned_result_list = None\n",
        "    def get_score_summary_df(self):\n",
        "        records = []\n",
        "        for info in self.score_list_ALL:\n",
        "            d = OrderedDict()\n",
        "            d[\"query_idx\"] = info[\"query_idx\"]\n",
        "            d[\"seq_id\"] = info[\"seq_id\"]\n",
        "            for i, refseq in enumerate(self.my_aligner.refseq_list):\n",
        "                d[f\"{refseq.path.name} (idx={i})\"]= info[\"score_list\"][2 * i]\n",
        "                d[f\"{refseq.path.name} (idx={i},rc)\"] = info[\"score_list\"][2 * i + 1]\n",
        "            for i, refseq in enumerate(self.my_aligner.refseq_list):\n",
        "                d[f\"{refseq.path.name} (idx={i}, normalized)\"]= info[\"normalized_score_list\"][2 * i]\n",
        "                d[f\"{refseq.path.name} (idx={i},rc, normalized)\"] = info[\"normalized_score_list\"][2 * i + 1]\n",
        "            d[\"assigned_refseq_idx\"] = info[\"assigned_refseq_idx\"]\n",
        "            d[\"is_reverse_compliment\"] = info[\"is_reverse_compliment\"]\n",
        "            d[\"assigned\"] = info[\"assigned\"]\n",
        "            records.append(d)\n",
        "        return pd.DataFrame.from_records(records)\n",
        "    def save_score_summary(self, save_path):\n",
        "        score_summary = (\n",
        "            \"query_idx\" \n",
        "            + \"\\tseq_id\" \n",
        "            + \"\\t\" \n",
        "            + \"\\t\".join([f\"{refseq.path.name} (idx={i})\\t{refseq.path.name} (idx={i},rc)\" for i, refseq in enumerate(self.my_aligner.refseq_list)])\n",
        "            + \"\\t\"\n",
        "            + \"\\t\".join([f\"{refseq.path.name} (idx={i}, normalized)\\t{refseq.path.name} (idx={i},rc, normalized)\" for i, refseq in enumerate(self.my_aligner.refseq_list)])\n",
        "            + \"\\tassigned_refseq_idx\"\n",
        "            + \"\\tis_reverse_compliment\"\n",
        "            + \"\\tassigned\\n\"\n",
        "            + \"\\n\".join(\n",
        "                [(\n",
        "                    str(info[\"query_idx\"])\n",
        "                    + \"\\t\" + info[\"seq_id\"]\n",
        "                    + \"\\t\" + \"\\t\".join(map(str, info[\"score_list\"]))\n",
        "                    + \"\\t\" + \"\\t\".join(map(str, info[\"normalized_score_list\"]))\n",
        "                    + \"\\t\" + str(info[\"assigned_refseq_idx\"])\n",
        "                    + \"\\t\" + str(info[\"is_reverse_compliment\"])\n",
        "                    + \"\\t\" + str(info[\"assigned\"])\n",
        "                ) for info in self.score_list_ALL]\n",
        "            )\n",
        "        )\n",
        "        with open(save_path, \"w\") as f:\n",
        "            f.write(score_summary)\n",
        "        return score_summary\n",
        "    def normalize_scores_and_apply_threshold(self):\n",
        "        self.score_list_ALL = []\n",
        "        self.result_info_assigned = [[] for i in self.my_aligner.refseq_list] # [[[seq_id, is_reverse_compliment, result, query_idx], ...], ...]\n",
        "        assert len(self.result_dict) == len(self.my_aligner.combined_fastq)\n",
        "        for query_idx, (seq_id, result_list) in enumerate(self.result_dict.items()):\n",
        "            assert len(result_list) == len(self.my_aligner.duplicated_refseq_seq_list) * 2\n",
        "            # normalize scores for each refseq\n",
        "            score_list = []\n",
        "            normalized_score_list = []\n",
        "            for result_idx, result in enumerate(result_list):\n",
        "                score_list.append(result.score)\n",
        "                duplicated_refseq_seq = self.my_aligner.duplicated_refseq_seq_list[result_idx // 2]\n",
        "                normalized_score = result.score / len(duplicated_refseq_seq) * 2\n",
        "                if normalized_score > 1:\n",
        "                    normalized_score = 1\n",
        "                normalized_score_list.append(normalized_score)\n",
        "            # choose sequence with maximum score\n",
        "            idx = np.argmax(normalized_score_list)\n",
        "            refseq_idx, is_reverse_compliment = divmod(idx, 2)\n",
        "            # quality check\n",
        "            assigned = (normalized_score_list[idx] >= self.score_threshold) & (len(self.my_aligner.combined_fastq[seq_id][0]) <= len(self.my_aligner.duplicated_refseq_seq_list[refseq_idx]))    # refseq の長さの二倍以上ある query_seq は omit する\n",
        "\n",
        "            # register\n",
        "            self.score_list_ALL.append({\n",
        "                \"query_idx\":query_idx, \n",
        "                \"seq_id\":seq_id, \n",
        "                \"score_list\":score_list, \n",
        "                \"normalized_score_list\":normalized_score_list, \n",
        "                \"assigned_refseq_idx\":refseq_idx, \n",
        "                \"is_reverse_compliment\":is_reverse_compliment, \n",
        "                \"assigned\":int(assigned)\n",
        "            })\n",
        "            if assigned:\n",
        "                self.result_info_assigned[refseq_idx].append([\n",
        "                    seq_id, \n",
        "                    is_reverse_compliment, \n",
        "                    result_list[idx], \n",
        "                    query_idx\n",
        "                ])\n",
        "    def integrate_assigned_result_info(self):\n",
        "        self.aligned_result_list = []\n",
        "        assert len(self.my_aligner.refseq_list) == len(self.result_info_assigned)\n",
        "        total_N = len(self.my_aligner.refseq_list)\n",
        "        for cur_idx, (refseq, result_info_list) in enumerate(zip(self.my_aligner.refseq_list, self.result_info_assigned)):\n",
        "            print(f\"\\rIntegrating alignment results: {cur_idx + 1} out of {total_N}\", end=\"\")\n",
        "            if len(result_info_list) > 0:\n",
        "                my_cigar_str_list = []\n",
        "                new_q_scores_list = []\n",
        "                new_seq_list = []\n",
        "                seq_id_list, is_reverse_compliment_list, result_list, query_idx_list = list(zip(*result_info_list))\n",
        "                for result, is_reverse_compliment, seq_id in zip(result_list, is_reverse_compliment_list, seq_id_list):\n",
        "                    # query info\n",
        "                    seq = self.my_aligner.combined_fastq[seq_id][0]\n",
        "                    q_scores = self.my_aligner.combined_fastq[seq_id][1]\n",
        "                    if is_reverse_compliment:\n",
        "                        seq = str(Seq(seq).reverse_complement())\n",
        "                        q_scores = q_scores[::-1]\n",
        "                    # results\n",
        "                    my_cigar_str = MyCigarStr(result.cigar)\n",
        "                    # organize alignment based on refseq\n",
        "                    number_of_ref_bases_before_query = result.beg_ref - result.beg_query\n",
        "                    number_of_ref_bases_after_query = (refseq.length * 2 - result.end_ref - 1) - (len(seq) - result.end_query - 1)\n",
        "                    \"\"\"\n",
        "                                beg_ref(9)      end_ref(24)\n",
        "                                     |                |\n",
        "                    pos     0         10         20         30\n",
        "                    ref     atcgatcggGGCTATG-CTTGCAT-GCatcgatcg\n",
        "                    align   HHHHHHHSS====X==I===D===N==SSSHHHHH\n",
        "                    query          caGGCTGTGACTT-CAT-GCtga\n",
        "                    pos            0         10          20\n",
        "                                     |                |         \n",
        "                                beg_query(2)    end_query(17)\n",
        "                    \"\"\"\n",
        "                    # truncate\n",
        "                    assert (number_of_ref_bases_before_query >= 0) or (number_of_ref_bases_after_query >= 0)\n",
        "                    if (number_of_ref_bases_before_query < 0):\n",
        "                        q_scores = q_scores[-number_of_ref_bases_before_query:]\n",
        "                        seq      = seq[-number_of_ref_bases_before_query:]\n",
        "                        result.beg_query -= -number_of_ref_bases_before_query\n",
        "                        result.end_query -= -number_of_ref_bases_before_query                        \n",
        "                        number_of_ref_bases_before_query = 0\n",
        "                    if (number_of_ref_bases_after_query < 0):\n",
        "                        q_scores = q_scores[:number_of_ref_bases_after_query]\n",
        "                        seq      = seq[:number_of_ref_bases_after_query]\n",
        "                        # result.beg_query # do nothing\n",
        "                        # result.end_query # do nothing\n",
        "                        number_of_ref_bases_after_query = 0\n",
        "                    assert (number_of_ref_bases_before_query >= 0) & (number_of_ref_bases_after_query >= 0)\n",
        "                    # organize my_cigar_str\n",
        "                    my_cigar_str = MyCigarStr(\n",
        "                        \"H\" * number_of_ref_bases_before_query      # add deletion of ref\n",
        "                        + \"S\" * result.beg_query                    # soft clip of query\n",
        "                        + my_cigar_str                              # aligned region\n",
        "                        + \"S\" * (len(seq) - result.end_query - 1)   # soft clip of query\n",
        "                        + \"H\" * number_of_ref_bases_after_query     # add deletion of ref\n",
        "                    )\n",
        "                    my_cigar_str = MyCigarStr(\n",
        "                        \"H\" * my_cigar_str.number_of_letters_on_5prime(\"HD\")    # なぜか parasail の結果で 5'側に D が連なっている場合があるので、それを除く（本来 beg_ref で調節されるべき？）\n",
        "                        + my_cigar_str.clip_from_both_ends(\"HD\")\n",
        "                        + \"H\" * my_cigar_str.number_of_letters_on_3prime(\"HD\")\n",
        "                    )\n",
        "                    my_cigar_str_H_clip = my_cigar_str.clip_from_both_ends(\"H\")\n",
        "                    assert len(q_scores) == len(seq) == len(my_cigar_str_H_clip) - my_cigar_str_H_clip.count(\"D\")\n",
        "                    assert refseq.length * 2 == len(my_cigar_str) - my_cigar_str_H_clip.count(\"I\")\n",
        "\n",
        "                    # なぜか parasail の結果で 5'側に I が連なっている場合があるので、それを除く（本来 beg_query で調節されるべき？）\n",
        "                    number_of_I_on_5prime = my_cigar_str.number_of_letters_on_5prime(\"I\")\n",
        "                    if number_of_I_on_5prime > 0:\n",
        "                        my_cigar_str = MyCigarStr(my_cigar_str[number_of_I_on_5prime:])\n",
        "                        q_scores = q_scores[number_of_I_on_5prime:]\n",
        "                        seq = seq[number_of_I_on_5prime:]\n",
        "\n",
        "                    my_cigar_str_list.append(my_cigar_str)\n",
        "                    new_q_scores_list.append(q_scores)\n",
        "                    new_seq_list.append(seq)\n",
        "                # further organize to match refseq, new_seq (query), and new_qscores.\n",
        "                my_cigar_str_net_length_list = [len(my_cigar_str) - my_cigar_str.count(\"I\") for my_cigar_str in my_cigar_str_list]\n",
        "                assert all(my_cigar_str_net_length_list[0] == x for x in my_cigar_str_net_length_list)\n",
        "\n",
        "                duplicated_refseq = refseq.seq + refseq.seq\n",
        "                duplicated_refseq_with_insertion = \"\"\n",
        "                my_cigar_str_list_with_insertion = [\"\" for i in my_cigar_str_list]\n",
        "                new_q_scores_list_with_insertion = [[] for i in new_q_scores_list]\n",
        "                new_seq_list_with_insertion = [\"\" for i in new_seq_list]\n",
        "\n",
        "                # print(duplicated_refseq)\n",
        "                # for i in new_seq_list:\n",
        "                #     print(i)\n",
        "\n",
        "                # current idx (positions of new_q_scores and new_seq are the same)\n",
        "                cur_refseq_idx = 0\n",
        "                cur_my_cigar_str_idx_list = [0 for i in my_cigar_str_list]\n",
        "                cur_q_scores_idx_list = [0 for i in new_q_scores_list]\n",
        "                max_refseq_idx = refseq.length * 2 - 1\n",
        "                max_my_cigar_str_idx_list = [len(my_cigar_str) - 1 for my_cigar_str in my_cigar_str_list]\n",
        "                max_q_scores_idx_list = [len(new_q_scores) - 1 for new_q_scores in new_q_scores_list]\n",
        "\n",
        "                # print(max_refseq_idx)\n",
        "                # print(max_my_cigar_str_idx_list)\n",
        "                # print(max_q_scores_idx_list)\n",
        "\n",
        "                all_done = False\n",
        "                cur_idx = -1\n",
        "                while not all_done:\n",
        "                    cur_idx += 1\n",
        "                    cur_my_cigar_letter_list = [my_cigar_str[cur_my_cigar_str_idx] for my_cigar_str, cur_my_cigar_str_idx in zip(my_cigar_str_list, cur_my_cigar_str_idx_list)]\n",
        "                    if \"I\" not in cur_my_cigar_letter_list:\n",
        "                        for i, L in enumerate(cur_my_cigar_letter_list):\n",
        "                            if L in \"DH\":\n",
        "                                my_cigar_str_list_with_insertion[i] += L\n",
        "                                new_q_scores_list_with_insertion[i] += [-1]\n",
        "                                new_seq_list_with_insertion[i]      += \"-\"\n",
        "                                cur_my_cigar_str_idx_list[i]        += 1\n",
        "                            elif L in \"SX=\":\n",
        "                                my_cigar_str_list_with_insertion[i] += L\n",
        "                                new_q_scores_list_with_insertion[i] += [ new_q_scores_list[i][cur_q_scores_idx_list[i]] ]\n",
        "                                new_seq_list_with_insertion[i]      += new_seq_list[i][cur_q_scores_idx_list[i]]\n",
        "                                cur_my_cigar_str_idx_list[i]        += 1\n",
        "                                cur_q_scores_idx_list[i]            += 1\n",
        "                            else:\n",
        "                                print(L)\n",
        "                                raise Exception(\"error!\")\n",
        "                        else:\n",
        "                            duplicated_refseq_with_insertion += duplicated_refseq[cur_refseq_idx]\n",
        "                            if cur_refseq_idx == refseq.length:\n",
        "                                turning_idx = cur_idx   # 後半開始\n",
        "                            cur_refseq_idx += 1\n",
        "                    else:\n",
        "                        # TODO: insertion 同士に関してはアラインメントしてないよ！\n",
        "                        for i, L in enumerate(cur_my_cigar_letter_list):\n",
        "                            if L == \"I\":\n",
        "                                my_cigar_str_list_with_insertion[i] += \"I\"\n",
        "                                new_q_scores_list_with_insertion[i] += [ new_q_scores_list[i][cur_q_scores_idx_list[i]] ]\n",
        "                                new_seq_list_with_insertion[i]      += new_seq_list[i][cur_q_scores_idx_list[i]]\n",
        "                                cur_my_cigar_str_idx_list[i]        += 1\n",
        "                                cur_q_scores_idx_list[i]            += 1\n",
        "                            else:\n",
        "                                my_cigar_str_list_with_insertion[i] += \"N\"\n",
        "                                new_q_scores_list_with_insertion[i] += [-1]\n",
        "                                new_seq_list_with_insertion[i]      += \"-\"\n",
        "                        else:\n",
        "                            duplicated_refseq_with_insertion += \"-\"\n",
        "\n",
        "                    # インデックスの最大値を参照して、すべて終わったら終える！\n",
        "                    all_done = bool(\n",
        "                        (cur_refseq_idx > max_refseq_idx)\n",
        "                        * all([cur_my_cigar_str_idx > max_my_cigar_str_idx for cur_my_cigar_str_idx, max_my_cigar_str_idx in zip(cur_my_cigar_str_idx_list, max_my_cigar_str_idx_list)])\n",
        "                        * all([cur_q_scores_idx > max_q_scores_idx for cur_q_scores_idx, max_q_scores_idx in zip(cur_q_scores_idx_list, max_q_scores_idx_list)])\n",
        "                    )\n",
        "                # print(duplicated_refseq_with_insertion)\n",
        "                # print(duplicated_refseq_with_insertion[turning_idx:])\n",
        "                for i in my_cigar_str_list_with_insertion:\n",
        "                    assert len(duplicated_refseq_with_insertion) == len(i)\n",
        "                for i in new_seq_list_with_insertion:\n",
        "                    assert len(duplicated_refseq_with_insertion) == len(i)\n",
        "                for i in new_q_scores_list_with_insertion:\n",
        "                    assert len(duplicated_refseq_with_insertion) == len(i)\n",
        "\n",
        "                # linearlize\n",
        "                refseq_with_insertion_1            = duplicated_refseq_with_insertion[:turning_idx]\n",
        "                refseq_with_insertion_2            = duplicated_refseq_with_insertion[turning_idx:]\n",
        "                assert (len(refseq_with_insertion_1) - refseq_with_insertion_1.count(\"-\")) == (len(refseq_with_insertion_2) - refseq_with_insertion_2.count(\"-\")) == refseq.length\n",
        "                my_cigar_str_list_with_insertion_1 = [i[:turning_idx] for i in my_cigar_str_list_with_insertion]\n",
        "                my_cigar_str_list_with_insertion_2 = [i[turning_idx:] for i in my_cigar_str_list_with_insertion]\n",
        "                new_seq_list_with_insertion_1      = [i[:turning_idx] for i in new_seq_list_with_insertion]\n",
        "                new_seq_list_with_insertion_2      = [i[turning_idx:] for i in new_seq_list_with_insertion]\n",
        "                new_q_scores_list_with_insertion_1 = [i[:turning_idx] for i in new_q_scores_list_with_insertion]\n",
        "                new_q_scores_list_with_insertion_2 = [i[turning_idx:] for i in new_q_scores_list_with_insertion]\n",
        "\n",
        "                # 前半と後半をアラインメント（insertionを考慮するだけで良い）\n",
        "                # 前半の末端処理\n",
        "                assert refseq_with_insertion_2[-1] != \"-\"\n",
        "                N_gap_refseq_with_insertion_1_end = 1\n",
        "                while True:\n",
        "                    if refseq_with_insertion_1[-N_gap_refseq_with_insertion_1_end] != \"-\":\n",
        "                        break\n",
        "                    N_gap_refseq_with_insertion_1_end += 1\n",
        "                if N_gap_refseq_with_insertion_1_end > 1:\n",
        "                    refseq_with_insertion_1 = refseq_with_insertion_1[:1 - N_gap_refseq_with_insertion_1_end]\n",
        "                    my_cigar_str_list_with_insertion_1 = [i[:1 - N_gap_refseq_with_insertion_1_end] for i in my_cigar_str_list_with_insertion_1]\n",
        "                    new_seq_list_with_insertion_1 = [i[:1 - N_gap_refseq_with_insertion_1_end] for i in new_seq_list_with_insertion_1]\n",
        "                    new_q_scores_list_with_insertion_1 = [i[:1 - N_gap_refseq_with_insertion_1_end] for i in new_q_scores_list_with_insertion_1]\n",
        "                # 前半後半アラインメント開始\n",
        "                idx = -1\n",
        "                refseq_idx1 = 0\n",
        "                refseq_idx2 = 0\n",
        "                refseq_max_idx1 = len(refseq_with_insertion_1) - 1\n",
        "                refseq_max_idx2 = len(refseq_with_insertion_2) - 1\n",
        "                while True:\n",
        "                    idx += 1\n",
        "                    if refseq_with_insertion_1[idx] == refseq_with_insertion_2[idx]:\n",
        "                        refseq_idx1 += 1\n",
        "                        refseq_idx2 += 1\n",
        "                    elif refseq_with_insertion_1[idx] == \"-\":\n",
        "                        refseq_idx1 += 1\n",
        "                        refseq_with_insertion_2 = refseq_with_insertion_2[:idx] + \"-\" + refseq_with_insertion_2[idx:]\n",
        "                        for i, j in enumerate(my_cigar_str_list_with_insertion_2):\n",
        "                            my_cigar_str_list_with_insertion_2[i] = j[:idx] + \"N\" + j[idx:]\n",
        "                        for i, j in enumerate(new_seq_list_with_insertion_2):\n",
        "                            new_seq_list_with_insertion_2[i]      = j[:idx] + \"-\" + j[idx:]\n",
        "                        for i in new_q_scores_list_with_insertion_2:\n",
        "                            i.insert(idx, -1)\n",
        "                    elif refseq_with_insertion_2[idx] == \"-\":\n",
        "                        refseq_idx2 += 1\n",
        "                        refseq_with_insertion_1 = refseq_with_insertion_1[:idx] + \"-\" + refseq_with_insertion_1[idx:]\n",
        "                        for i, j in enumerate(my_cigar_str_list_with_insertion_1):\n",
        "                            my_cigar_str_list_with_insertion_1[i] = j[:idx] + \"N\" + j[idx:]\n",
        "                        for i, j in enumerate(new_seq_list_with_insertion_1):\n",
        "                            new_seq_list_with_insertion_1[i]      = j[:idx] + \"-\" + j[idx:]\n",
        "                        for i in new_q_scores_list_with_insertion_1:\n",
        "                            i.insert(idx, -1)\n",
        "                    else:\n",
        "                        raise Exception(\"error!\")\n",
        "                    # end\n",
        "                    if (refseq_idx1 == refseq_max_idx1) & (refseq_idx2 == refseq_max_idx2):\n",
        "                        break\n",
        "                # check\n",
        "                assert refseq_with_insertion_1 == refseq_with_insertion_2\n",
        "                for i in my_cigar_str_list_with_insertion_1:\n",
        "                    assert len(refseq_with_insertion_1) == len(i)\n",
        "                for i in my_cigar_str_list_with_insertion_2:\n",
        "                    assert len(refseq_with_insertion_2) == len(i)\n",
        "                for i in new_seq_list_with_insertion_1:\n",
        "                    assert len(refseq_with_insertion_1) == len(i)\n",
        "                for i in new_seq_list_with_insertion_2:\n",
        "                    assert len(refseq_with_insertion_2) == len(i)\n",
        "                for i in new_q_scores_list_with_insertion_1:\n",
        "                    assert len(refseq_with_insertion_1) == len(i)\n",
        "                for i in new_q_scores_list_with_insertion_2:\n",
        "                    assert len(refseq_with_insertion_2) == len(i)\n",
        "\n",
        "                # print(\"Alighment of top half and bottom half: DONE\")\n",
        "\n",
        "                # スコアマキシマムになるような前半後半の境界を探す\n",
        "                custom_cigar_score_dict = self.my_aligner.get_custom_cigar_score_dict()\n",
        "                refseq_with_insertion = refseq_with_insertion_1\n",
        "                my_cigar_str_list_with_insertion = [None for i in my_cigar_str_list_with_insertion_1]\n",
        "                new_seq_list_with_insertion = [None for i in new_seq_list_with_insertion_1]\n",
        "                new_q_scores_list_with_insertion = [None for i in new_q_scores_list_with_insertion_1]\n",
        "                for i, (j1, j2, k1, k2, l1, l2) in enumerate(zip(\n",
        "                        my_cigar_str_list_with_insertion_1, \n",
        "                        my_cigar_str_list_with_insertion_2, \n",
        "                        new_seq_list_with_insertion_1, \n",
        "                        new_seq_list_with_insertion_2, \n",
        "                        new_q_scores_list_with_insertion_1, \n",
        "                        new_q_scores_list_with_insertion_2\n",
        "                )):\n",
        "                    my_cigar_scores_with_insertion_1 = np.array([custom_cigar_score_dict[j] for j in j1])\n",
        "                    my_cigar_scores_with_insertion_2 = np.array([custom_cigar_score_dict[j] for j in j2])\n",
        "                    switching_idx = np.argmin(np.cumsum(my_cigar_scores_with_insertion_1 - my_cigar_scores_with_insertion_2))\n",
        "                    # register\n",
        "                    my_cigar_str_list_with_insertion[i] = j2[:switching_idx + 1] + j1[switching_idx + 1:]\n",
        "                    new_seq_list_with_insertion[i]      = k2[:switching_idx + 1] + k1[switching_idx + 1:]\n",
        "                    new_q_scores_list_with_insertion[i] = l2[:switching_idx + 1] + l1[switching_idx + 1:]\n",
        "\n",
        "                # print(seq_id_list)\n",
        "                # print(refseq_with_insertion)\n",
        "                # for i, seq_id in enumerate(seq_id_list):\n",
        "                #     # print(seq_id)\n",
        "                #     print(my_cigar_str_list_with_insertion[i])\n",
        "                #     print(new_seq_list_with_insertion[i])\n",
        "                #     print(new_q_scores_list_with_insertion[i])\n",
        "                self.aligned_result_list.append({\n",
        "                    \"refseq_with_insertion\": refseq_with_insertion, \n",
        "                    \"query_idx_list\": query_idx_list, \n",
        "                    \"seq_id_list\": seq_id_list, \n",
        "                    \"my_cigar_str_list_with_insertion\": my_cigar_str_list_with_insertion, \n",
        "                    \"new_seq_list_with_insertion\": new_seq_list_with_insertion, \n",
        "                    \"new_q_scores_list_with_insertion\": new_q_scores_list_with_insertion\n",
        "                })\n",
        "            else:\n",
        "                self.aligned_result_list.append({\n",
        "                    \"refseq_with_insertion\": refseq.seq, \n",
        "\n",
        "                    \"query_idx_list\": (), \n",
        "                    \"seq_id_list\": (), \n",
        "                    \"my_cigar_str_list_with_insertion\": [], \n",
        "                    \"new_seq_list_with_insertion\": [], \n",
        "                    \"new_q_scores_list_with_insertion\": []\n",
        "\n",
        "                    # \"query_idx_list\": (-1, ), \n",
        "                    # \"seq_id_list\": (\"@None\", ), \n",
        "                    # \"my_cigar_str_list_with_insertion\": [\"X\" * len(refseq.seq)], \n",
        "                    # \"new_seq_list_with_insertion\": [\"-\" * len(refseq.seq)], \n",
        "                    # \"new_q_scores_list_with_insertion\": [[-1] * len(refseq.seq)]\n",
        "                })\n",
        "        assert len(self.my_aligner.refseq_list) == len(self.aligned_result_list)\n",
        "    def export_as_text(self, save_dir):\n",
        "        text_list = []\n",
        "        save_path_list = []\n",
        "        for refseq, aligned_result in zip(self.my_aligner.refseq_list, self.aligned_result_list):\n",
        "            text = \"\"\n",
        "            idx_label_minimum = \"consensus\"\n",
        "            query_idx_list = aligned_result[\"query_idx_list\"]\n",
        "            query_idx_len_max = max([len(str(query_idx)) for query_idx in query_idx_list] + [0])\n",
        "            label_N0 = max(query_idx_len_max, len(idx_label_minimum)) + 1\n",
        "            seq_id_list = aligned_result[\"seq_id_list\"]\n",
        "            seq_id_len_max = max([len(seq_id) for seq_id in seq_id_list] + [0])\n",
        "            label_N1 = max(seq_id_len_max, len(refseq.path.name)) + 1\n",
        "            text += (\n",
        "                \"ref\"\n",
        "                + \" \" * (label_N0 - 3)\n",
        "                + refseq.path.name\n",
        "                + \" \" * (label_N1 - len(refseq.path.name))\n",
        "                + aligned_result[\"refseq_with_insertion\"]\n",
        "            )\n",
        "            consensus_seq, consensus_q_scores, consensus_seq_all, consensus_q_scores_all = self.consensus_dict[refseq.path.name]\n",
        "            text += (\n",
        "                \"\\n\"\n",
        "                + \"consensus\"\n",
        "                + \" \" * (label_N0 - 9 + label_N1)\n",
        "                + consensus_seq_all\n",
        "            )\n",
        "            text += (\n",
        "                \"\\n\"\n",
        "                + \"consensus\"\n",
        "                + \" \" * (label_N0 - 9 + label_N1)\n",
        "                + \"\".join([chr(q) for q in (np.array(consensus_q_scores_all) + 33)])\n",
        "            )\n",
        "            for query_idx, seq_id, my_cigar_str_with_insertion, new_seq_with_insertion, new_q_scores_with_insertion in \\\n",
        "                zip(\n",
        "                    aligned_result[\"query_idx_list\"], \n",
        "                    aligned_result[\"seq_id_list\"], \n",
        "                    aligned_result[\"my_cigar_str_list_with_insertion\"], \n",
        "                    aligned_result[\"new_seq_list_with_insertion\"], \n",
        "                    aligned_result[\"new_q_scores_list_with_insertion\"]\n",
        "                ):\n",
        "                label = (\n",
        "                    \"\\n\"\n",
        "                    + str(query_idx)\n",
        "                    + \" \" * (label_N0 - len(str(query_idx)))\n",
        "                    + seq_id\n",
        "                    + \" \" * (label_N1 - len(seq_id))\n",
        "                )\n",
        "                text += (\n",
        "                    label\n",
        "                    + new_seq_with_insertion\n",
        "                    + label\n",
        "                    + my_cigar_str_with_insertion\n",
        "                    + label\n",
        "                    + \"\".join([chr(q) for q in (np.array(new_q_scores_with_insertion) + 33)])\n",
        "                )\n",
        "            save_path = (save_dir / refseq.path.name).with_suffix(\".txt\")\n",
        "            with open(save_path, \"w\") as f:\n",
        "                f.write(text)\n",
        "            text_list.append(text)\n",
        "            save_path_list.append(save_path)\n",
        "        return text_list, save_path_list\n",
        "    def alignment_reuslt_list_2_text_list(self, linewidth=\"\"):\n",
        "        text_list = []\n",
        "        highlight_pos_list = []\n",
        "        refseq_name_list = []\n",
        "        for refseq, aligned_result in zip(self.my_aligner.refseq_list, self.aligned_result_list):\n",
        "            ref_label = \"REF\"\n",
        "            label_N = max(len(str(max(aligned_result[\"query_idx_list\"]))), len(ref_label)) + 1\n",
        "            refseq_name_list.append(refseq.path.name)\n",
        "            # \"linewidth\" 行ごとにまとめて改行\n",
        "            child_lines = re.findall(fr\".{{1,{linewidth}}}\", aligned_result[\"refseq_with_insertion\"].upper())\n",
        "            master_lines = [list(map(lambda l: ref_label + \" \" * (label_N - len(ref_label)) + l, child_lines))]\n",
        "            for idx, (new_seq_with_insertion, query_idx) in enumerate(zip(aligned_result[\"new_seq_list_with_insertion\"], aligned_result[\"query_idx_list\"])):\n",
        "                child_lines = re.findall(fr\".{{1,{linewidth}}}\", new_seq_with_insertion.upper())\n",
        "                master_lines.append(list(map(lambda l: f\"{query_idx}\" + \" \" * (label_N - len(str(query_idx))) + l, child_lines)))\n",
        "            # 改行したものを zip でくっつけていく\n",
        "            text = \"\"\n",
        "            for i, lines in enumerate(zip(*master_lines)):\n",
        "                text += (\n",
        "                    f\"{i * linewidth + 1}-{(i + 1) * linewidth}\\n\"\n",
        "                    + \"\\n\".join(lines)\n",
        "                    + \"\\n\\n\"\n",
        "                )\n",
        "            text_list.append(text.strip())\n",
        "            # ハイライト部分\n",
        "            highlight_pos_in_text = []\n",
        "            for i, my_cigar_str_with_insertion in enumerate(aligned_result[\"my_cigar_str_list_with_insertion\"]):\n",
        "                # print(len(my_cigar_str_with_insertion))\n",
        "                true_highlight_pos = [m.start() for m in re.finditer('[IXDS]', my_cigar_str_with_insertion)]\n",
        "                for p in true_highlight_pos:\n",
        "                    r, c = divmod(p, linewidth) \n",
        "                    r = r * (len(master_lines) + 2) + i + 2 # ポジション行、master_lines、改行空白\n",
        "                    c += label_N\n",
        "                    highlight_pos_in_text.append((r, c))\n",
        "            highlight_pos_list.append(highlight_pos_in_text)\n",
        "        return refseq_name_list, text_list, highlight_pos_list\n",
        "    def export_log(self, save_path, header):\n",
        "        text = (\n",
        "            header\n",
        "            + f\"\\n{datetime.datetime.now()}\"\n",
        "            + \"\\n\\ninput reference files\"\n",
        "            + \"\\n\"\n",
        "            + \"\\n\".join([refseq.path.as_posix() for refseq in self.my_aligner.refseq_list])\n",
        "            + \"\\n\\ninput fastq files\"\n",
        "            + \"\\n\"\n",
        "            + \"\\n\".join([fastq_path.as_posix() for fastq_path in self.my_aligner.combined_fastq.path])\n",
        "            + \"\\n\\nalignment params\"\n",
        "            + f\"\\ngap_open_penalty\\t{self.my_aligner.gap_open_penalty}\"\n",
        "            + f\"\\ngap_extend_penalty\\t{self.my_aligner.gap_extend_penalty}\"\n",
        "            + f\"\\nmatch_score\\t{self.my_aligner.match_score}\"\n",
        "            + f\"\\nmismatch_score\\t{self.my_aligner.mismatch_score}\"\n",
        "            + f\"\\nscore_threshold\\t{self.score_threshold}\"\n",
        "            + \"\\n\"\n",
        "            + \"\\n\".join(f\"custom_cigar_score '{k}'\\t{v}\" for k, v in self.my_aligner.get_custom_cigar_score_dict().items())\n",
        "            + \"\\n\\nscore_matrix (basically the same as match_score and mismatch_score)\"\n",
        "            + \"\\n\"\n",
        "            + self.matrix2string(self.my_aligner.my_custom_matrix.matrix, digit=3, round=True)\n",
        "            + \"\\n\"\n",
        "            + \"\\nconsensus_settings\"\n",
        "            + \"\\nsbq_pdf_version\\t\" + self.consensus_settings[\"sbq_pdf_version\"]\n",
        "            + \"\\n\"\n",
        "            + \"\\nerror_matrix (row:true_base, col:base_calling , val:P(true_base|base_calling))\"\n",
        "            + \"\\n\"\n",
        "            + self.matrix2string(\n",
        "                self.consensus_settings[\"P_N_dict_matrix\"], \n",
        "                bases=self.consensus_settings[\"bases\"], \n",
        "                digit=None, \n",
        "                round=False\n",
        "            )\n",
        "        )\n",
        "        with open(save_path, \"w\") as f:\n",
        "            f.write(text)\n",
        "    @staticmethod\n",
        "    def matrix2string(matrix, bases=\"ATCG\", digit=3, round=True):\n",
        "        bio = io.BytesIO()\n",
        "        if round:\n",
        "            np.savetxt(bio, matrix, fmt=f\"%{digit}d\")\n",
        "        else:\n",
        "            np.savetxt(bio, matrix, fmt=f\"%.5e\")\n",
        "            digit = 11\n",
        "        matrix_str = bio.getvalue().decode('latin1')\n",
        "        bases = bases + \"*\"\n",
        "        output = (\n",
        "            \" \" * (digit + 1)\n",
        "            + (\" \" * digit).join(b for b in bases)\n",
        "        )\n",
        "        for b, m in zip(bases, matrix_str.split(\"\\n\")):\n",
        "            output += f\"\\n{b} {m}\"\n",
        "        return output\n",
        "    def save_consensus(self, save_dir):\n",
        "        save_path_list = []\n",
        "        for key, val in self.consensus_dict.items():\n",
        "            save_path1 = save_dir / Path(key).with_suffix(\".fastq\")\n",
        "            consensus_seq, consensus_q_scores, *all_results = val\n",
        "            consensus_q_scores = \"\".join([chr(q + 33) for q in consensus_q_scores])\n",
        "            consensus_fastq_txt = f\"@{key}:\\n{consensus_seq.upper()}\\n+\\n{consensus_q_scores}\"\n",
        "            with open(save_path1, \"w\") as f:\n",
        "                f.write(consensus_fastq_txt)\n",
        "            save_path_list.append(save_path1)\n",
        "        return save_path_list\n",
        "\n",
        "def draw_distributions(score_summary_df, combined_fastq):\n",
        "    refseq_idx_dict = OrderedDict()\n",
        "    for c in score_summary_df.columns:\n",
        "        m = re.match(r\"(.+) \\(idx=([0-9]+)\\)\", c)\n",
        "        if m is not None:\n",
        "            refseq_idx_dict[int(m.group(2))] = m.group(1)\n",
        "\n",
        "    # データ収集\n",
        "    assignment_set_4_read_length = [[] for i in range(len(refseq_idx_dict) + 1)]   # last one is for idx=-1 (not assigned)\n",
        "    assignment_set_4_q_scores = [[] for i in range(len(refseq_idx_dict) + 1)]   # last one is for idx=-1 (not assigned)\n",
        "    for i, s in score_summary_df.iterrows():\n",
        "        seq_id = s[\"seq_id\"]\n",
        "        assigned_refseq_idx = s[\"assigned_refseq_idx\"]\n",
        "        assigned = s[\"assigned\"]\n",
        "        if assigned == 0:\n",
        "            assigned_refseq_idx = -1\n",
        "        assignment_set_4_read_length[assigned_refseq_idx].append(len(combined_fastq[seq_id][0]))\n",
        "        assignment_set_4_q_scores[assigned_refseq_idx].extend(combined_fastq[seq_id][1])\n",
        "\n",
        "    # 描画パラメータ\n",
        "    rows = len(refseq_idx_dict)\n",
        "    columns = 3 # 4\n",
        "    fig = plt.figure(figsize=(4 * columns, 2 * rows), clear=True)\n",
        "    fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
        "    widths = [2] + [2 for i in range(columns - 1)]\n",
        "    # heights = [2] + [3 for i in range(rows - 1)]\n",
        "    spec = fig.add_gridspec(ncols=columns, nrows=rows, width_ratios=widths)#, height_ratios=heights)\n",
        "\n",
        "    ###########\n",
        "    # labeles #\n",
        "    ###########\n",
        "    column_idx = 0\n",
        "    text_wrap = 15\n",
        "    for refseq_idx, refseq_name in refseq_idx_dict.items():\n",
        "        ax = fig.add_subplot(spec[refseq_idx, column_idx])\n",
        "        refseq_name_wrapped = \"\\n\".join([refseq_name[i:i+text_wrap] for i in range(0, len(refseq_name), text_wrap)])\n",
        "        ax.text(0.5, 0.6, refseq_name_wrapped, ha='center', va='center', wrap=True, family=\"monospace\")\n",
        "        ax.set_axis_off()\n",
        "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=color_cycle[0], label='Focused'), \n",
        "        Patch(facecolor=color_cycle[1], label='Others'), \n",
        "        Patch(facecolor=\"grey\", label='not assigned')\n",
        "    ]\n",
        "    fig.legend(handles=legend_elements, loc=\"lower left\", borderaxespad=0)\n",
        "\n",
        "    ############################\n",
        "    # read length distribution #\n",
        "    ############################\n",
        "    column_idx = 1\n",
        "    # assignment ごとにヒートマップを描画\n",
        "    bin_unit = 100\n",
        "    bins = range(0, int(np.ceil(max(max(v) if len(v) > 0 else bin_unit for v in assignment_set_4_read_length) / bin_unit) * bin_unit), bin_unit)\n",
        "    for refseq_idx, refseq_name in refseq_idx_dict.items():\n",
        "        hist_params = dict(\n",
        "            x=assignment_set_4_read_length[-2::-1] + assignment_set_4_read_length[-1:], \n",
        "            color=[color_cycle[0] if i == refseq_idx else color_cycle[1] for i in range(len(refseq_idx_dict))][::-1] + [\"grey\"], \n",
        "            bins=bins, \n",
        "            histtype='bar', \n",
        "            stacked=True\n",
        "        )\n",
        "        # 描画\n",
        "        ax0 = fig.add_subplot(spec[refseq_idx, column_idx])\n",
        "        ax0.hist(**hist_params)\n",
        "        ax0.set_ylabel(\"count\")\n",
        "        # # log scale\n",
        "        # ax1 = fig.add_subplot(spec[refseq_idx, column_idx + 1])\n",
        "        # ax1.hist(**hist_params)\n",
        "        # ax1.set_yscale(\"log\")\n",
        "        # ax1.set_ylabel(\"count\")\n",
        "        if refseq_idx == 0:\n",
        "            ax0.set_title(\"read length distribution\")\n",
        "            # ax1.set_title(\"read length distribution (log)\")\n",
        "        if refseq_idx == len(refseq_idx_dict) - 1:\n",
        "            ax0.set_xlabel(\"bp\")\n",
        "            # ax1.set_xlabel(\"bp\")\n",
        "        else:\n",
        "            ax0.set_xticklabels([])\n",
        "            # ax1.set_xticklabels([])\n",
        "\n",
        "    ########################\n",
        "    # q_score distribution #\n",
        "    ########################\n",
        "    column_idx = 2\n",
        "    for refseq_idx, refseq_name in refseq_idx_dict.items():\n",
        "        hist_params = dict(\n",
        "            x=assignment_set_4_q_scores[-2::-1] + assignment_set_4_q_scores[-1:], \n",
        "            color=[color_cycle[0] if i == refseq_idx else color_cycle[1] for i in range(len(refseq_idx_dict))][::-1] + [\"grey\"], \n",
        "            bins=np.arange(42), \n",
        "            histtype='bar', \n",
        "            stacked=True, \n",
        "            density=True\n",
        "        )\n",
        "        # 描画\n",
        "        ax0 = fig.add_subplot(spec[refseq_idx, column_idx])\n",
        "        ax0.hist(**hist_params)\n",
        "\n",
        "        # labels\n",
        "        ax0.set_ylabel(\"density\")\n",
        "        if refseq_idx == 0:\n",
        "            ax0.set_title(\"Q-score distribution\")\n",
        "        if refseq_idx == len(refseq_idx_dict) - 1:\n",
        "            ax0.set_xlabel(\"Q-score\")\n",
        "        else:\n",
        "            ax0.set_xticklabels([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "def draw_alignment_score_scatter(score_summary_df, score_threshold):\n",
        "    refseq_idx_dict = OrderedDict()\n",
        "    for c in score_summary_df.columns:\n",
        "        m = re.match(r\"(.+) \\(idx=([0-9]+)\\)\", c)\n",
        "        if m is not None:\n",
        "            refseq_idx_dict[int(m.group(2))] = m.group(1)\n",
        "\n",
        "    # アサインされたスコアまとめを追加\n",
        "    for refseq_idx, refseq_name in refseq_idx_dict.items():\n",
        "        col_name1 = refseq_name + f\" (idx={refseq_idx}, normalized)\"\n",
        "        col_name2 = refseq_name + f\" (idx={refseq_idx},rc, normalized)\"\n",
        "        score_summary_df[refseq_name] = score_summary_df.apply(lambda row: max(row[col_name1], row[col_name2]), axis=1)\n",
        "\n",
        "    # 描画パラメータ\n",
        "    rows = columns = len(refseq_idx_dict) + 1\n",
        "    color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
        "    focused_color1 = color_cycle[0]\n",
        "    focused_color2 = color_cycle[1]\n",
        "    not_assigned_color = \"grey\"\n",
        "    fig = plt.figure(figsize=(2.5 * columns, 2.5 * rows), clear=True)\n",
        "    widths = [2] + [3 for i in range(columns - 1)]\n",
        "    heights = [2] + [3 for i in range(columns - 1)]\n",
        "    spec = fig.add_gridspec(ncols=columns, nrows=rows, width_ratios=widths, height_ratios=heights)\n",
        "\n",
        "    # label\n",
        "    legend_elements = [\n",
        "        Patch(facecolor=color_cycle[0], label='Focused'), \n",
        "        Patch(facecolor=color_cycle[1], label='Others'), \n",
        "        Patch(facecolor=\"grey\", label='not assigned')\n",
        "    ]\n",
        "    fig.legend(handles=legend_elements, loc=\"upper left\", borderaxespad=0.2)\n",
        "    # fig.suptitle(\"alignment score scatter\")\n",
        "\n",
        "    ######################\n",
        "    # score distribution #\n",
        "    ######################\n",
        "    diagonal_axes = []\n",
        "    other_axes = []\n",
        "    for (refseq_idx1, refseq_name1), (refseq_idx2, refseq_name2) in product(refseq_idx_dict.items(), refseq_idx_dict.items()):\n",
        "        ax = fig.add_subplot(spec[refseq_idx1 + 1, refseq_idx2 + 1]) # 原点を左上にに取った！\n",
        "        if refseq_idx1 == refseq_idx2:\n",
        "            diagonal_axes.append(ax)\n",
        "            hist_params = dict(\n",
        "                x=[\n",
        "                    score_summary_df.query(\"(assigned_refseq_idx == @refseq_idx1)&(assigned == 1)\")[refseq_name1], \n",
        "                    score_summary_df.query(\"(assigned_refseq_idx != @refseq_idx1)&(assigned == 1)\")[refseq_name1], \n",
        "                    score_summary_df.query(\"(assigned == 0)\")[refseq_name1]\n",
        "                ], \n",
        "                color=[focused_color1, focused_color2, not_assigned_color], \n",
        "                bins=np.linspace(0, 1, 100), \n",
        "                histtype='bar', \n",
        "                stacked=True, \n",
        "                density=True\n",
        "            )\n",
        "            ax.hist(**hist_params)\n",
        "        else:\n",
        "            other_axes.append(ax)\n",
        "            scatter_params = dict(\n",
        "                x=refseq_name2, \n",
        "                y=refseq_name1, \n",
        "                ax=ax, \n",
        "                s=5, \n",
        "                alpha=0.3\n",
        "            )\n",
        "            plot_params = dict(\n",
        "                c=\"k\", \n",
        "                linestyle=\"--\", \n",
        "                linewidth=1\n",
        "            )\n",
        "            score_summary_df.query(\"(assigned_refseq_idx == @refseq_idx2)&(assigned == 1)\").plot.scatter(color=focused_color1, **scatter_params)\n",
        "            score_summary_df.query(\"(assigned_refseq_idx != @refseq_idx2)&(assigned == 1)\").plot.scatter(color=focused_color2, **scatter_params)\n",
        "            score_summary_df.query(\"assigned == 0\").plot.scatter(color=not_assigned_color, **scatter_params)\n",
        "            ax.plot((score_threshold, score_threshold), (0, score_threshold), **plot_params)\n",
        "            ax.plot((0, score_threshold), (score_threshold, score_threshold), **plot_params)\n",
        "            ax.plot((score_threshold, 1), (score_threshold, 1), **plot_params)\n",
        "            ax.set_ylim(-0.05, 1.05)\n",
        "        ax.set_xlim(-0.05, 1.05)\n",
        "        ax.set_xticks(np.linspace(0, 1, 6))\n",
        "        ax.set_xticklabels([\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
        "        if refseq_idx2 != 0:\n",
        "            # ax.yaxis.set_ticks_position('none')\n",
        "            ax.set(ylabel=None)\n",
        "            plt.setp(ax.get_yticklabels(), visible=False)\n",
        "        else:\n",
        "            if refseq_idx1 == refseq_idx2:\n",
        "                ax.set_ylabel(\"density\")\n",
        "            else:\n",
        "                ax.set_ylabel(\"normalized alignment score\")\n",
        "                ax.set_yticks(np.linspace(0, 1, 6))\n",
        "                ax.set_yticklabels([\"0.0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"])\n",
        "        if refseq_idx1 != rows - 2:\n",
        "            # ax.xaxis.set_ticks_position('none')\n",
        "            ax.set(xlabel=None)\n",
        "            plt.setp(ax.get_xticklabels(), visible=False)\n",
        "        else:\n",
        "            ax.set_xlabel(\"normalized alignment score\")\n",
        "\n",
        "    range_max = max(ax.get_ylim()[1] for ax in diagonal_axes)\n",
        "    for ax in diagonal_axes:\n",
        "        ax.set_ylim(0, range_max)\n",
        "\n",
        "    text_wrap = 15\n",
        "    for refseq_idx, refseq_name in refseq_idx_dict.items():\n",
        "        ax = fig.add_subplot(spec[0, refseq_idx + 1])\n",
        "        refseq_name_wrapped = \"\\n\".join([refseq_name[i:i+text_wrap] for i in range(0, len(refseq_name), text_wrap)])\n",
        "        ax.text(0.5, 0.0, refseq_name_wrapped, ha='center', va='bottom', wrap=True, family=\"monospace\")\n",
        "        ax.set_axis_off()\n",
        "\n",
        "        ax = fig.add_subplot(spec[refseq_idx + 1, 0])\n",
        "        refseq_name_wrapped = \"\\n\".join([refseq_name[i:i+text_wrap] for i in range(0, len(refseq_name), text_wrap)])\n",
        "        ax.text(0.5, 0.4, refseq_name_wrapped, ha='right', va='center', wrap=True, family=\"monospace\")\n",
        "        ax.set_axis_off()\n",
        "\n",
        "    # set aspect after setting the ylim\n",
        "    # ax = other_axes[0]\n",
        "    # aspect = (ax.get_xlim()[1] - ax.get_xlim()[0]) / (ax.get_ylim()[1] - ax.get_ylim()[0])\n",
        "    # for ax in other_axes:\n",
        "    #     ax.set_aspect(aspect, adjustable='box')\n",
        "    ax = diagonal_axes[0]\n",
        "    aspect_diagonal = (ax.get_xlim()[1] - ax.get_xlim()[0]) / (ax.get_ylim()[1] - ax.get_ylim()[0])\n",
        "    for ax in diagonal_axes:\n",
        "        ax.set_aspect(aspect_diagonal, adjustable='box')\n",
        "    fig.subplots_adjust(hspace=0.05, wspace=0.05, left=0.0, right=0.8, bottom=0.2, top=1.0)\n",
        "\n",
        "alignment_result = AlignmentResult(result_dict, my_aligner)\n",
        "print(\"normalizing scores...\")\n",
        "alignment_result.normalize_scores_and_apply_threshold()\n",
        "print(\"normalization: DONE\")\n",
        "score_summary_df = alignment_result.get_score_summary_df()\n",
        "\n",
        "# draw graphical summary\n",
        "print(\"drawing figures...\")\n",
        "draw_distributions(score_summary_df, my_aligner.combined_fastq)\n",
        "draw_alignment_score_scatter(score_summary_df, alignment_result.score_threshold)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv-S4MbEgnGN",
        "outputId": "45916115-7c16-4ac9-a700-20fc931027ab"
      },
      "outputs": [],
      "source": [
        "#@title # 4. Calculate consensus\n",
        "\n",
        "error_rate = 0.0001   #@param {type:\"number\"}\n",
        "del_mut_rate = error_rate / 4     # e.g. \"A -> T, C, G, del\"\n",
        "ins_rate   = 0.0001 #@param {type:\"number\"}   # 挿入は独立に考える？\n",
        "\n",
        "##\n",
        "bases = \"ATCG-\"\n",
        "assert bases[-1] == \"-\"\n",
        "\n",
        "from collections import defaultdict\n",
        "default_value = {b_key2:ins_rate / 4 if b_key2 != \"-\" else 1 - ins_rate for b_key2 in bases}\n",
        "\n",
        "P_N_dict_dict = defaultdict(\n",
        "    lambda: default_value, \n",
        "    {   # 真のベースが b_key1 である場合に、b_key2 への mutation/deletion などが起こる確率\n",
        "        b_key1:{b_key2:1 - error_rate if b_key2 == b_key1 else del_mut_rate for b_key2 in bases} for b_key1 in bases[:-1]  # remove \"-\" from b_key1\n",
        "    }\n",
        ")\n",
        "P_N_dict_dict[\"-\"] = default_value\n",
        "\n",
        "default_value_2 = {b_key2:0.2 / 4 if b_key2 != \"-\" else 0.8 for b_key2 in bases}\n",
        "P_N_dict_dict_2 = defaultdict(\n",
        "    lambda: default_value_2, \n",
        "    {\n",
        "        b_key1:{b_key2: 0.2 for b_key2 in bases} for b_key1 in bases[::-1]\n",
        "    }\n",
        ")\n",
        "P_N_dict_dict_2[\"-\"] = default_value_2\n",
        "letter_code_dict = {\n",
        "    \"ATCG\":\"N\", # Any base\n",
        "    \"TCG\":\"B\",  # Not A\n",
        "    \"ACG\":\"V\",  # Not T\n",
        "    \"ATG\":\"D\",  # Not C\n",
        "    \"ATC\":\"H\",  # Not G\n",
        "    \"TG\":\"K\",   # Keto\n",
        "    \"AC\":\"M\",   # Amino\n",
        "    \"AG\":\"R\",   # Purine\n",
        "    \"CG\":\"S\",   # Strong\n",
        "    \"AT\":\"W\",   # Weak\n",
        "    \"TC\":\"Y\",   # Pyrimidine\n",
        "    \"A\":\"A\", \n",
        "    \"T\":\"T\", \n",
        "    \"C\":\"C\", \n",
        "    \"G\":\"G\", \n",
        "}\n",
        "def mixed_bases(base_list):\n",
        "    if len(base_list) == 1:\n",
        "        return base_list[0]\n",
        "    elif \"-\" not in base_list:\n",
        "        pass\n",
        "    else:\n",
        "        base_list.remove(\"-\")\n",
        "    letters = \"\"\n",
        "    for b in bases[:-1]:\n",
        "        if b in base_list:\n",
        "            letters += b\n",
        "    return letter_code_dict[letters]\n",
        "\n",
        "def P_N_dict_dict_2_matrix(P_N_dict_dict, bases=bases):\n",
        "    r_matrix = np.empty((len(bases), len(bases)), dtype=float)\n",
        "    for r, b_key1 in enumerate(bases):\n",
        "        for c, b_key2 in enumerate(bases):\n",
        "            r_matrix[r, c] = P_N_dict_dict[b_key1][b_key2]\n",
        "    return r_matrix\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def fopen(filein, *args, **kwargs):\n",
        "    if isinstance(filein, str) or isinstance(filein, Path):  # filename/Path\n",
        "        with open(filein, *args, **kwargs) as f:\n",
        "            yield f\n",
        "    else:  # file-like object\n",
        "        yield filein\n",
        "\n",
        "class MyTextFormat():\n",
        "    def to_text(self):\n",
        "        text = \"\"\n",
        "        for k, data_type in self.keys:\n",
        "            text += f\"# {k}({data_type})\\n\"\n",
        "            v = getattr(self, k)\n",
        "            if data_type in (\"str\", \"int\"):\n",
        "                string = str(v)\n",
        "            elif data_type == \"ndarray\":\n",
        "                with io.StringIO() as s:\n",
        "                    np.savetxt(s, v)\n",
        "                    string = s.getvalue().strip()\n",
        "            elif data_type == \"list\":\n",
        "                string = \"\\n\".join(v)\n",
        "            elif data_type in (\"dict\", \"OrderedDict\"):\n",
        "                string = \"\\n\".join(f\"{k}\\t{v}\" for k, v in v.items())\n",
        "            elif data_type == \"eval\":\n",
        "                string = v.__str__()\n",
        "            elif data_type == \"df\":\n",
        "                string_io = io.StringIO()\n",
        "                v.to_csv(string_io, sep=\"\\t\")\n",
        "                string = string_io.getvalue().strip(\"\\n\")\n",
        "            else:\n",
        "                raise Exception(f\"unsupported data type: {type(v)}\")\n",
        "            text += f\"{string}\\n\\n\"\n",
        "        return text\n",
        "    def save(self, save_path):\n",
        "        text = self.to_text()\n",
        "        with open(save_path, \"w\") as f:\n",
        "            f.write(text)\n",
        "    def load(self, load_path):\n",
        "        added_keys = []\n",
        "        with fopen(load_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "        cur_k = None\n",
        "        cur_v = None\n",
        "        cur_data_type = None\n",
        "        for l in lines:\n",
        "            if l.startswith(\"# \"):\n",
        "                if cur_k is None:   pass\n",
        "                else:   self.set_attribute(cur_k, cur_v[:-2], cur_data_type)    # 改行コードが２つ入るので除く\n",
        "                m = re.match(r\"^(.+)\\((.+)\\)$\", l[2:].strip(\"\\n\"))\n",
        "                cur_k = m.group(1)\n",
        "                cur_data_type = m.group(2)\n",
        "                cur_v = \"\"\n",
        "                added_keys.append((cur_k, cur_data_type))\n",
        "            else:\n",
        "                cur_v += l\n",
        "        else:\n",
        "            self.set_attribute(cur_k, cur_v[:-2], cur_data_type)\n",
        "        return added_keys\n",
        "    def set_attribute(self, cur_k: str, cur_v: str, cur_data_type: str):\n",
        "        if isinstance(getattr(type(self), cur_k, None), property):\n",
        "            if getattr(type(self), cur_k).fset is None:\n",
        "                return\n",
        "        if cur_data_type == \"str\":\n",
        "            v = cur_v\n",
        "        elif cur_data_type == \"ndarray\":\n",
        "            v = np.array([list(map(float, line.split())) for line in cur_v.split(\"\\n\")])\n",
        "        elif cur_data_type == \"list\":\n",
        "            v = self.convert_to_number_if_possible(cur_v.split(\"\\n\"), method=\"all\")\n",
        "        elif cur_data_type == \"dict\":\n",
        "            v = {l.split(\"\\t\")[0]:l.split(\"\\t\")[1] for l in cur_v.split(\"\\n\")}\n",
        "        elif cur_data_type == \"OrderedDict\":\n",
        "            v = OrderedDict([l.split(\"\\t\") for l in cur_v.split(\"\\n\")])\n",
        "        elif cur_data_type == \"eval\":\n",
        "            v = eval(cur_v)\n",
        "        elif cur_data_type == \"df\":\n",
        "            from ast import literal_eval\n",
        "            string_io = io.StringIO(cur_v)\n",
        "            v = pd.read_csv(string_io, sep=\"\\t\", index_col=0, dtype=str)\n",
        "        else:\n",
        "            raise Exception(f\"unsupported data type\\n{cur_data_type}\")\n",
        "        setattr(self, cur_k, v)\n",
        "    def convert_to_number_if_possible(self, values, method):\n",
        "        new_values = []\n",
        "        for v in values:\n",
        "            try:\n",
        "                new_values.append(float(v))\n",
        "            except:\n",
        "                new_values.append(v)\n",
        "        if (method == \"all\") and any(map(lambda x: not isinstance(x, float), new_values)):\n",
        "            return values\n",
        "        else:\n",
        "            return new_values\n",
        "\n",
        "class SequenceBasecallQscoreLibrary(MyTextFormat):\n",
        "    def __init__(self, path=None) -> None:\n",
        "        self.file_version = version\n",
        "        self.path = path\n",
        "        self.master_params_dict = None\n",
        "        self.meta_info = pd.DataFrame()\n",
        "        self.alignment_summary = pd.DataFrame(columns=[\"=\", \"I\", \"D\", \"X\", \"H\", \"S\", \"aligned_query_len\", \"refseq_len\", \"score\"], dtype=object)\n",
        "        # info for saving\n",
        "        self.keys = [\n",
        "            (\"file_version\", \"str\"),\n",
        "            (\"master_params_dict\", \"dict\"),\n",
        "            (\"meta_info\", \"df\"), \n",
        "            (\"alignment_summary\", \"df\"), \n",
        "        ]\n",
        "        self.variable_key_start_idx = 4\n",
        "        # load\n",
        "        if self.path is not None:\n",
        "            self.load(load_path=self.path)\n",
        "        # when pdf\n",
        "        if (len(self.keys) > 4) and (self.keys[4][0] == \"sum\"):\n",
        "            self.initialize_pdf()\n",
        "    def copy_key_data(self, lib):\n",
        "        for k, d_type in self.keys:\n",
        "            setattr(self, k, copy.deepcopy(getattr(lib, k)))\n",
        "    def get_sum(self, pdf_params_dict):\n",
        "        lib_sum = self.__class__()\n",
        "        lib_sum.copy_key_data(self)\n",
        "        lib_sum.path = self.path.parent / (self.path.stem + f\"_sum{self.path.suffix}\")\n",
        "        # combine all data\n",
        "        combined_df, loc = self.combine_data(**pdf_params_dict)\n",
        "        combined_df = combined_df.astype(object).astype(int)\n",
        "        lib_sum.add_df_by_dict(OrderedDict(\n",
        "            [(\"sum\", combined_df)]\n",
        "        ))\n",
        "        # add params and records\n",
        "        for k, v in pdf_params_dict.items():\n",
        "            lib_sum.master_params_dict[k] = v\n",
        "        lib_sum.alignment_summary[\"used_for_pdf\"] = loc\n",
        "        return lib_sum\n",
        "    def add_df_by_dict(self, ordered_dict: OrderedDict):\n",
        "        for k, v in ordered_dict.items():\n",
        "            setattr(self, k, v)\n",
        "            self.keys.append((k, \"df\"))\n",
        "    def combine_data(self, threshold, thredhold_type, **kwargs):\n",
        "        if thredhold_type == \"score_over_aligned_query_len\":\n",
        "            extracted_summary = self.alignment_summary.astype(float).query(\"(score / aligned_query_len) > @threshold\")\n",
        "            loc = self.alignment_summary.astype(float).apply(lambda x: x[\"score\"] / x[\"aligned_query_len\"], axis=1) > threshold\n",
        "        else:\n",
        "            raise Exception(\"error!\")\n",
        "        assert len(extracted_summary.index) > 0\n",
        "        df = pd.DataFrame(0, index=getattr(self, extracted_summary.index[0]).index, columns=getattr(self, extracted_summary.index[0]).columns, dtype=float)\n",
        "        for key in  extracted_summary.index:\n",
        "            new_df = getattr(self, key)\n",
        "            assert all(df.index == new_df.index) and all(df.columns == new_df.columns)\n",
        "            df += new_df.astype(float)\n",
        "        return df, loc\n",
        "    def save(self, save_path=None):\n",
        "        if save_path is None:\n",
        "            save_path = self.path\n",
        "        else:\n",
        "            self.path = save_path\n",
        "        super().save(save_path)\n",
        "    def load(self, load_path):\n",
        "        added_keys = super().load(load_path)\n",
        "        for i in range(self.variable_key_start_idx):\n",
        "            assert added_keys[i] == self.keys[i]\n",
        "        for k in added_keys[self.variable_key_start_idx:]:\n",
        "            self.keys.append(k)\n",
        "        # post-processing\n",
        "        self.meta_info[\"refseq_info\"] = self.meta_info[\"refseq_info\"].apply(lambda x: eval(x))\n",
        "        for k, v in self.master_params_dict.items():\n",
        "            try:    self.master_params_dict[k] = int(v) # int\n",
        "            except: self.master_params_dict[k] = v      # string\n",
        "        self.path = load_path\n",
        "    def register_meta_info(self, fastq, refseq_list, **kwargs):\n",
        "        meta_string = self.generate_meta_info_key(fastq)\n",
        "        assert meta_string not in self.meta_info.index.values\n",
        "        self.meta_info.loc[meta_string, \"refseq_info\"] = [[f\"{refseq.my_hash}:{refseq.path.name}\"] for refseq in refseq_list]\n",
        "        for k, v in kwargs.items():\n",
        "            self.meta_info.loc[meta_string, k] = v\n",
        "    def register_alignment_summary(self, summary_info_dict, **kwargs):\n",
        "        for key, d in summary_info_dict.items():\n",
        "            for k, v in d.items():\n",
        "                self.alignment_summary.loc[key, k] = v\n",
        "    @staticmethod\n",
        "    def generate_meta_info_key(fastq):\n",
        "        return f\"{fastq.my_hash}:{fastq.path.name}\"\n",
        "    @staticmethod\n",
        "    def summary_df_2_matrix(summary_df:pd.DataFrame, base_order=None, **kwargs):\n",
        "        crushed = summary_df.sum(axis=0)\n",
        "        summary_matrix = np.zeros(shape=(len(base_order), len(base_order)), dtype=float)\n",
        "        for k, v in crushed.items():\n",
        "            m = re.match(r\"(.+)_(.+)\", k)\n",
        "            ref_base = m.group(1)\n",
        "            query_base = m.group(2)\n",
        "            summary_matrix[base_order.index(ref_base), base_order.index(query_base)] = v\n",
        "        return summary_matrix\n",
        "\n",
        "    #########################\n",
        "    # PDF related functions #\n",
        "    #########################\n",
        "    def initialize_pdf(self):\n",
        "        assert self.keys[4][0] == \"sum\"\n",
        "        self.sum = self.sum.astype(int)\n",
        "        # 確率 0 となるのを避ける\n",
        "        for c in self.sum.columns:\n",
        "            if c.endswith(\"-\"):\n",
        "                continue\n",
        "            for i in self.sum.index:\n",
        "                if i < 2:\n",
        "                    continue\n",
        "                if self.sum.at[i, c] == 0:\n",
        "                    self.sum.at[i, c] += 1\n",
        "        # bunbo\n",
        "        total_events_when_true_base = {}\n",
        "        for column_names, values in self.sum.items():\n",
        "            true_base = column_names.split(\"_\")[0]\n",
        "            if true_base not in total_events_when_true_base.keys():\n",
        "                total_events_when_true_base[true_base] = values.sum()\n",
        "            else:\n",
        "                total_events_when_true_base[true_base] += values.sum()\n",
        "        # calc probability\n",
        "        self.P_base_calling_given_true_refseq_dict = {}\n",
        "        for column_names, values in self.sum.items():\n",
        "            true_base = column_names.split(\"_\")[0]\n",
        "            self.P_base_calling_given_true_refseq_dict[column_names] = values.sum() / total_events_when_true_base[true_base]\n",
        "        # others\n",
        "        self.pdf_core = {}\n",
        "        for column_names, values in self.sum.items():\n",
        "            assert all(values.index == np.arange(-1, 42))\n",
        "            values /= values.sum()\n",
        "            # マイナス1で最後のやつにアクセスできるようにする（さすがに50も間を開けてれば、q-scoreがかぶってくることは無いでしょう…）\n",
        "            values_list = list(values)[1:] + [0.0 for i in range(50)] + list(values)[:1]\n",
        "            self.pdf_core[column_names] = values\n",
        "    # example:  a = self.calc_P_event_given_true_refseq(event=(\"T\", 30), true_refseq=\"T\")\n",
        "    def calc_P_event_given_true_refseq(self, event, true_refseq):\n",
        "        readseq, q_score = event\n",
        "        key = f\"{true_refseq}_{readseq}\"\n",
        "        return (\n",
        "            self.P_base_calling_given_true_refseq_dict[key]\n",
        "            * self.pdf_core[key][q_score]\n",
        "        )\n",
        "    def calc_consensus_error_rate(self, event_list, true_refseq, P_N_dict, bases):\n",
        "        bunbo_bunshi_sum = 0\n",
        "        bunshi_list = [self.calc_P_event_given_true_refseq(event, true_refseq) for event in event_list]\n",
        "        bunshi_P_N = P_N_dict[true_refseq]\n",
        "        # inside sum\n",
        "        for base in bases:\n",
        "            val = P_N_dict[base] / bunshi_P_N\n",
        "            for event, bunshi in zip(event_list, bunshi_list):\n",
        "                val *= self.calc_P_event_given_true_refseq(event, base) / bunshi\n",
        "            bunbo_bunshi_sum += val\n",
        "        return 1 - 1 / bunbo_bunshi_sum\n",
        "\n",
        "NanoporeStats_PDF_txt = textwrap.dedent(\"\"\"\n",
        "    # file_version(str)\n",
        "    0.2.0\n",
        "\n",
        "    # master_params_dict(dict)\n",
        "    gap_open_penalty\t3\n",
        "    gap_extend_penalty\t1\n",
        "    match_score\t1\n",
        "    mismatch_score\t-2\n",
        "    base_length_2_observe\t1\n",
        "    threshold\t0.6\n",
        "    thredhold_type\tscore_over_aligned_query_len\n",
        "\n",
        "    # meta_info(df)\n",
        "    \trefseq_info\n",
        "    omitted.fastq\t['omitted.fasta']\n",
        "\n",
        "    # alignment_summary(df)\n",
        "    \t=\tI\tD\tX\tH\tS\taligned_query_len\trefseq_len\tscore\tused_for_pdf\n",
        "    omitted_id\t-1\t-1\t-1\t-1\t-1\t-1\t-1\t-1\t-1\tTrue\n",
        "\n",
        "    # sum(df)\n",
        "    \tA_A\tA_T\tA_C\tA_G\tA_-\tT_A\tT_T\tT_C\tT_G\tT_-\tC_A\tC_T\tC_C\tC_G\tC_-\tG_A\tG_T\tG_C\tG_G\tG_-\t-_A\t-_T\t-_C\t-_G\t-_-\n",
        "    -1\t0\t0\t0\t0\t8999\t0\t0\t0\t0\t7112\t0\t0\t0\t0\t11317\t0\t0\t0\t0\t11289\t0\t0\t0\t0\t6107251\n",
        "    0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "    1\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\t0\n",
        "    2\t426\t10\t18\t42\t0\t23\t340\t26\t11\t0\t62\t34\t372\t40\t0\t81\t22\t28\t380\t0\t50\t21\t30\t26\t0\n",
        "    3\t1409\t36\t85\t163\t0\t35\t1263\t90\t49\t0\t117\t87\t1477\t127\t0\t224\t48\t118\t1691\t0\t164\t95\t115\t145\t0\n",
        "    4\t3406\t72\t184\t338\t0\t87\t3048\t144\t73\t0\t213\t181\t3645\t209\t0\t484\t118\t182\t4025\t0\t349\t231\t260\t341\t0\n",
        "    5\t6053\t75\t227\t496\t0\t105\t5323\t209\t104\t0\t297\t234\t6258\t281\t0\t709\t115\t261\t7043\t0\t500\t288\t367\t505\t0\n",
        "    6\t8591\t85\t261\t611\t0\t98\t7093\t215\t106\t0\t303\t252\t8927\t356\t0\t870\t96\t275\t9851\t0\t656\t346\t455\t589\t0\n",
        "    7\t11716\t87\t297\t714\t0\t103\t9555\t227\t94\t0\t316\t263\t12075\t322\t0\t992\t105\t373\t13710\t0\t653\t365\t451\t643\t0\n",
        "    8\t12193\t76\t253\t748\t0\t84\t9965\t206\t86\t0\t276\t255\t12926\t287\t0\t1002\t95\t316\t14210\t0\t609\t340\t431\t571\t0\n",
        "    9\t11699\t56\t223\t657\t0\t56\t9736\t188\t62\t0\t230\t201\t12742\t258\t0\t894\t78\t276\t13925\t0\t571\t307\t394\t518\t0\n",
        "    10\t11142\t68\t200\t532\t0\t52\t9166\t163\t54\t0\t183\t166\t11856\t220\t0\t771\t56\t239\t13184\t0\t494\t305\t328\t442\t0\n",
        "    11\t10884\t39\t152\t418\t0\t34\t9128\t113\t37\t0\t139\t158\t11887\t169\t0\t601\t57\t200\t12733\t0\t454\t264\t300\t400\t0\n",
        "    12\t10689\t45\t113\t385\t0\t43\t9039\t119\t23\t0\t132\t126\t11849\t143\t0\t541\t34\t172\t12313\t0\t398\t236\t306\t360\t0\n",
        "    13\t10550\t30\t96\t291\t0\t33\t9135\t87\t22\t0\t107\t127\t11604\t128\t0\t459\t34\t130\t12436\t0\t323\t218\t239\t324\t0\n",
        "    14\t10593\t39\t63\t264\t0\t26\t9015\t73\t13\t0\t92\t127\t11872\t103\t0\t418\t35\t135\t12676\t0\t310\t190\t237\t299\t0\n",
        "    15\t10512\t20\t84\t219\t0\t17\t9192\t58\t16\t0\t71\t99\t12312\t71\t0\t359\t31\t107\t12539\t0\t257\t219\t201\t271\t0\n",
        "    16\t10780\t34\t65\t221\t0\t21\t9392\t54\t19\t0\t59\t88\t12563\t66\t0\t310\t29\t86\t13057\t0\t232\t180\t211\t202\t0\n",
        "    17\t10843\t26\t59\t169\t0\t17\t9289\t63\t16\t0\t41\t61\t12766\t57\t0\t281\t17\t79\t13102\t0\t227\t153\t181\t195\t0\n",
        "    18\t11027\t13\t45\t148\t0\t17\t9761\t61\t16\t0\t54\t65\t12987\t63\t0\t220\t18\t78\t13440\t0\t210\t132\t164\t199\t0\n",
        "    19\t11470\t15\t45\t130\t0\t11\t10142\t54\t8\t0\t47\t45\t13721\t46\t0\t215\t13\t54\t14029\t0\t177\t142\t137\t192\t0\n",
        "    20\t11936\t14\t36\t118\t0\t5\t10610\t39\t20\t0\t31\t47\t14134\t38\t0\t195\t18\t44\t14509\t0\t154\t141\t126\t167\t0\n",
        "    21\t12248\t10\t30\t114\t0\t7\t10970\t27\t10\t0\t33\t38\t14727\t37\t0\t176\t16\t46\t15021\t0\t133\t123\t157\t158\t0\n",
        "    22\t12759\t13\t25\t88\t0\t9\t11309\t26\t6\t0\t28\t45\t15618\t36\t0\t152\t16\t36\t15891\t0\t131\t145\t131\t142\t0\n",
        "    23\t13413\t7\t23\t88\t0\t12\t11814\t25\t5\t0\t27\t25\t16359\t35\t0\t155\t9\t33\t16541\t0\t128\t143\t149\t136\t0\n",
        "    24\t14338\t7\t19\t75\t0\t8\t13022\t19\t4\t0\t29\t26\t17435\t23\t0\t127\t4\t27\t17893\t0\t104\t125\t130\t116\t0\n",
        "    25\t15154\t7\t23\t66\t0\t4\t13434\t16\t5\t0\t16\t26\t18684\t21\t0\t121\t8\t30\t19223\t0\t98\t117\t156\t105\t0\n",
        "    26\t16154\t4\t13\t52\t0\t5\t14733\t12\t2\t0\t13\t28\t20212\t14\t0\t92\t7\t25\t20598\t0\t101\t140\t137\t101\t0\n",
        "    27\t17541\t6\t8\t48\t0\t1\t15844\t9\t2\t0\t14\t22\t21975\t15\t0\t108\t4\t23\t22447\t0\t112\t140\t106\t105\t0\n",
        "    28\t19297\t2\t11\t41\t0\t3\t17711\t5\t5\t0\t14\t15\t24315\t17\t0\t75\t2\t21\t24780\t0\t119\t113\t124\t98\t0\n",
        "    29\t21224\t1\t15\t38\t0\t3\t19865\t16\t0\t0\t13\t23\t27098\t10\t0\t77\t4\t16\t27354\t0\t99\t155\t132\t83\t0\n",
        "    30\t24032\t4\t9\t21\t0\t3\t22599\t11\t5\t0\t15\t15\t30276\t13\t0\t65\t1\t10\t30460\t0\t101\t123\t142\t116\t0\n",
        "    31\t27448\t1\t5\t32\t0\t0\t26257\t11\t0\t0\t5\t15\t33926\t11\t0\t47\t2\t7\t34298\t0\t94\t136\t169\t109\t0\n",
        "    32\t31166\t3\t3\t27\t0\t1\t30015\t5\t0\t0\t5\t10\t38340\t7\t0\t44\t7\t5\t38796\t0\t108\t145\t167\t109\t0\n",
        "    33\t35026\t2\t4\t17\t0\t2\t34652\t8\t1\t0\t8\t9\t42458\t6\t0\t46\t2\t9\t42678\t0\t115\t128\t127\t111\t0\n",
        "    34\t39313\t2\t6\t13\t0\t0\t39155\t7\t0\t0\t8\t7\t47036\t7\t0\t53\t0\t4\t47352\t0\t117\t160\t206\t116\t0\n",
        "    35\t43784\t4\t5\t15\t0\t0\t43501\t4\t2\t0\t5\t6\t51506\t8\t0\t26\t3\t7\t52394\t0\t113\t167\t155\t111\t0\n",
        "    36\t48503\t1\t3\t7\t0\t2\t48846\t5\t1\t0\t9\t8\t56565\t3\t0\t28\t1\t6\t56832\t0\t125\t145\t155\t106\t0\n",
        "    37\t53503\t1\t3\t10\t0\t1\t55312\t5\t0\t0\t5\t3\t62160\t7\t0\t37\t1\t2\t62695\t0\t121\t189\t121\t102\t0\n",
        "    38\t58885\t0\t4\t9\t0\t0\t61504\t3\t1\t0\t7\t3\t67806\t2\t0\t22\t4\t6\t67856\t0\t126\t173\t144\t124\t0\n",
        "    39\t64020\t0\t4\t7\t0\t3\t68218\t4\t1\t0\t3\t5\t73282\t4\t0\t22\t1\t1\t72869\t0\t135\t170\t142\t105\t0\n",
        "    40\t69864\t0\t1\t7\t0\t1\t74745\t2\t0\t0\t1\t3\t79278\t0\t0\t17\t1\t3\t77279\t0\t124\t183\t93\t96\t0\n",
        "    41\t612803\t4\t3\t17\t0\t0\t649004\t6\t3\t0\t9\t9\t673360\t3\t0\t64\t3\t7\t650025\t0\t684\t891\t599\t538\t0\n",
        "\"\"\").strip() + \"\\n\\n\"\n",
        "\n",
        "sbq_pdf = SequenceBasecallQscoreLibrary(io.StringIO(NanoporeStats_PDF_txt))\n",
        "\n",
        "def calc_consensus(self, sbq_pdf, P_N_dict_dict):\n",
        "    self.consensus_dict = {}\n",
        "    for refseq_idx, aligned_result in enumerate(self.aligned_result_list):\n",
        "        print(f\"\\nrefseq No. {refseq_idx}\")\n",
        "        consensus_seq = \"\"\n",
        "        consensus_q_scores = []\n",
        "        consensus_seq_all = \"\"\n",
        "        consensus_q_scores_all = []\n",
        "        N_bases = len(aligned_result[\"refseq_with_insertion\"])\n",
        "        for refbase_idx, refbase in enumerate(aligned_result[\"refseq_with_insertion\"]):\n",
        "            print(f\"\\r{refbase_idx + 1} out of {N_bases}\", end=\"\")\n",
        "            seq_base_list = [i[refbase_idx] for i in aligned_result[\"new_seq_list_with_insertion\"]]\n",
        "            q_score_list = [i[refbase_idx] for i in aligned_result[\"new_q_scores_list_with_insertion\"]]\n",
        "            event_list = [(i.upper(), j) for i, j in zip(seq_base_list, q_score_list)]\n",
        "\n",
        "            P_N_dict = P_N_dict_dict[refbase.upper()]\n",
        "            p_list = [\n",
        "                sbq_pdf.calc_consensus_error_rate(event_list, true_refseq=B, P_N_dict=P_N_dict, bases=bases)\n",
        "                for B in bases\n",
        "            ]\n",
        "            p = min(p_list)\n",
        "            # p_idx_list = [i for i, v in enumerate(p_list) if v == p]\n",
        "            consensus_base_call = mixed_bases([b for b, tmp_p in zip(bases, p_list) if tmp_p == p])\n",
        "\n",
        "            # register\n",
        "            if p >= 10 ** (-5):\n",
        "                q_score = np.round(-10 * np.log10(p)).astype(int)\n",
        "            elif p < 0:\n",
        "                raise Exception(\"unknown error\")\n",
        "            else:\n",
        "                q_score = 50\n",
        "            if  consensus_base_call != \"-\":\n",
        "                consensus_seq += consensus_base_call\n",
        "                consensus_q_scores.append(q_score)\n",
        "\n",
        "            # registre \"all\" results\n",
        "            consensus_seq_all += consensus_base_call\n",
        "            consensus_q_scores_all.append(q_score)\n",
        "\n",
        "        # 登録\n",
        "        self.consensus_dict[self.my_aligner.refseq_list[refseq_idx].path.name] = [\n",
        "            consensus_seq, \n",
        "            consensus_q_scores, \n",
        "            consensus_seq_all, \n",
        "            consensus_q_scores_all\n",
        "        ]\n",
        "    # register settings\n",
        "    self.consensus_settings = {\n",
        "        \"sbq_pdf_version\":sbq_pdf.file_version, \n",
        "        \"P_N_dict_matrix\":P_N_dict_dict_2_matrix(P_N_dict_dict), \n",
        "        \"bases\": bases\n",
        "    }\n",
        "\n",
        "alignment_result.integrate_assigned_result_info()\n",
        "print()\n",
        "print(\"integration: DONE\")\n",
        "\n",
        "print(\"Calculating consensus with prior information...\")\n",
        "calc_consensus(alignment_result, sbq_pdf, P_N_dict_dict)\n",
        "print(\"\\n\\nCalculating consensus without prior information...\")\n",
        "alignment_result_2 = copy.deepcopy(alignment_result)\n",
        "calc_consensus(alignment_result_2, sbq_pdf, P_N_dict_dict_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tcTfIX4tC-R9"
      },
      "outputs": [],
      "source": [
        "#@title # 5. Export results\n",
        "export_alignment_image = False # @ param {type:\"boolean\"}\n",
        "Size = namedtuple('Size', (\"ax0\", \"ax1\"))\n",
        "class ATCG_5x5_img():\n",
        "    dtype = uint8\n",
        "    # bases\n",
        "    A = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [1,1,1,1], \n",
        "        [1,0,0,1], \n",
        "        [1,0,0,1]\n",
        "    ], dtype=dtype)\n",
        "    C = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [1,0,0,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    G = np.array([\n",
        "        [0,1,1,1], \n",
        "        [1,0,0,0], \n",
        "        [1,0,1,1], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    T = np.array([\n",
        "        [1,1,1,0], \n",
        "        [0,1,0,0], \n",
        "        [0,1,0,0], \n",
        "        [0,1,0,0], \n",
        "        [0,1,0,0]\n",
        "    ], dtype=dtype)\n",
        "    # special letters\n",
        "    R = np.array([\n",
        "        [1,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [1,1,1,0], \n",
        "        [1,0,1,0], \n",
        "        [1,0,0,1]\n",
        "    ], dtype=dtype)\n",
        "    E = np.array([\n",
        "        [1,1,1,1], \n",
        "        [1,0,0,0], \n",
        "        [1,1,1,0], \n",
        "        [1,0,0,0], \n",
        "        [1,1,1,1]\n",
        "    ], dtype=dtype)\n",
        "    F = np.array([\n",
        "        [1,1,1,1], \n",
        "        [1,0,0,0], \n",
        "        [1,1,1,0], \n",
        "        [1,0,0,0], \n",
        "        [1,0,0,0]\n",
        "    ], dtype=dtype)\n",
        "    # numbers\n",
        "    zero = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [1,0,0,1], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    one = np.array([\n",
        "        [0,1,0,0], \n",
        "        [1,1,0,0], \n",
        "        [0,1,0,0], \n",
        "        [0,1,0,0], \n",
        "        [1,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    two = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,0,1,0], \n",
        "        [0,1,0,0], \n",
        "        [1,1,1,1]\n",
        "    ], dtype=dtype)\n",
        "    three = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,0,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    four = np.array([\n",
        "        [0,0,1,0], \n",
        "        [0,1,1,0], \n",
        "        [1,0,1,0], \n",
        "        [1,1,1,1], \n",
        "        [0,0,1,0]\n",
        "    ], dtype=dtype)\n",
        "    five = np.array([\n",
        "        [1,1,1,0], \n",
        "        [1,0,0,0], \n",
        "        [1,1,1,0], \n",
        "        [0,0,0,1], \n",
        "        [1,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    six = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,0], \n",
        "        [1,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    seven = np.array([\n",
        "        [1,1,1,1], \n",
        "        [0,0,0,1], \n",
        "        [0,0,1,0], \n",
        "        [0,1,0,0], \n",
        "        [0,1,0,0]\n",
        "    ], dtype=dtype)\n",
        "    eight = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    nine = np.array([\n",
        "        [0,1,1,0], \n",
        "        [1,0,0,1], \n",
        "        [0,1,1,1], \n",
        "        [0,0,0,1], \n",
        "        [0,1,1,0]\n",
        "    ], dtype=dtype)\n",
        "    hyphen = np.array([\n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0], \n",
        "        [1,1,1,1], \n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0]\n",
        "    ])\n",
        "    blank = np.array([\n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0], \n",
        "        [0,0,0,0]\n",
        "    ])\n",
        "    w2n = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
        "    s2n = {\"-\":\"hyphen\", \" \":\"blank\"}\n",
        "    def __init__(self, ax0, ax1, ax0_space=2, ax1_space=1):\n",
        "        # prefixed\n",
        "        self.letter_size = Size(ax0=5, ax1=4)\n",
        "        self.bit = int(re.match(fr\"^uint([0-9]+)$\", self.dtype.__name__).group(1))\n",
        "        self.max_intensity = 2 ** self.bit - 1\n",
        "        # not prefixed\n",
        "        self.size = Size(ax0=ax0, ax1=ax1)\n",
        "        self.space = Size(ax0=ax0_space, ax1=ax1_space)\n",
        "        self.actual_size = Size(\n",
        "            ax0=self.size.ax0 * (self.letter_size.ax0 + self.space.ax0) + self.space.ax0, \n",
        "            ax1=self.size.ax1 * (self.letter_size.ax1 + self.space.ax1) + self.space.ax1\n",
        "        )\n",
        "        self.img_R = np.ones(self.actual_size, dtype=self.dtype) * self.max_intensity\n",
        "        self.img_G = np.ones(self.actual_size, dtype=self.dtype) * self.max_intensity\n",
        "        self.img_B = np.ones(self.actual_size, dtype=self.dtype) * self.max_intensity\n",
        "        self.letter_matrix = np.empty(self.size, dtype=str)\n",
        "    def write_letters(self, ax0, ax1, letters):\n",
        "        for letter in letters:\n",
        "            self.write_letter(ax0, ax1, letter)\n",
        "            ax1 += 1\n",
        "    def write_letter(self, ax0, ax1, letter):\n",
        "        self.letter_matrix[ax0, ax1] = letter\n",
        "        if letter in \"0123456789\":\n",
        "            letter = self.w2n[int(letter)]\n",
        "        elif letter in \"- \":\n",
        "            letter = self.s2n[letter]\n",
        "        letter_array = getattr(self, letter)\n",
        "        actual_ax0 = ax0 * (self.letter_size.ax0 + self.space.ax0) + self.space.ax0\n",
        "        actual_ax1 = ax1 * (self.letter_size.ax1 + self.space.ax1) + self.space.ax1\n",
        "        self.img_R[actual_ax0:actual_ax0 + self.letter_size.ax0, actual_ax1:actual_ax1 + self.letter_size.ax1] = (1 - letter_array) * self.max_intensity\n",
        "        self.img_G[actual_ax0:actual_ax0 + self.letter_size.ax0, actual_ax1:actual_ax1 + self.letter_size.ax1] = (1 - letter_array) * self.max_intensity\n",
        "        self.img_B[actual_ax0:actual_ax0 + self.letter_size.ax0, actual_ax1:actual_ax1 + self.letter_size.ax1] = (1 - letter_array) * self.max_intensity\n",
        "    def highlight_letters(self, ax0, ax1, color, length):\n",
        "        for i in range(length):\n",
        "            self.highlight_letter(ax0, ax1 + i, color)\n",
        "    def highlight_letter(self, ax0, ax1, color):\n",
        "        letter = self.letter_matrix[ax0, ax1]\n",
        "        if letter == \"-\":\n",
        "            letter = self.s2n[letter]\n",
        "        letter_array = getattr(self, letter)\n",
        "        actual_ax0 = ax0 * (self.letter_size.ax0 + self.space.ax0) + self.space.ax0\n",
        "        actual_ax1 = ax1 * (self.letter_size.ax1 + self.space.ax1) + self.space.ax1\n",
        "        for img, color_value in zip([self.img_R, self.img_G, self.img_B], color):\n",
        "            highlighted_letter = (1 - letter_array) * color_value\n",
        "            img[actual_ax0:actual_ax0 + self.letter_size.ax0, actual_ax1:actual_ax1 + self.letter_size.ax1] = highlighted_letter\n",
        "    def export_as_img(self, save_path, max_row_per_img):\n",
        "        rgb_stack = np.stack((self.img_R, self.img_G, self.img_B), axis=2)\n",
        "        N = np.ceil(self.size[0] / max_row_per_img).astype(int)\n",
        "        save_paths = []\n",
        "        for i in range(N):\n",
        "            save_path_tmp = save_path.parent / f\"{save_path.stem}_{i}{save_path.suffix}\"\n",
        "            save_paths.append(save_path_tmp)\n",
        "            s = i * max_row_per_img       * (self.letter_size.ax0 + self.space.ax0) + self.space.ax0\n",
        "            e = (i + 1) * max_row_per_img * (self.letter_size.ax0 + self.space.ax0) + self.space.ax0\n",
        "            Image.fromarray(rgb_stack[s:e,:,:]).save(save_path_tmp)\n",
        "        return save_paths\n",
        "\n",
        "all_file_paths = []\n",
        "# export settings\n",
        "print(\"Exporting logs...\")\n",
        "header = f\"{app_name} ver{version}\\n{description}\"\n",
        "save_path_log_1 = pwd / \"log_with_prior.txt\"\n",
        "\n",
        "alignment_result.export_log(save_path_log_1, header=header)\n",
        "all_file_paths.append(save_path_log_1)\n",
        "\n",
        "save_path_log_2 = pwd / \"log_without_prior.txt\"\n",
        "alignment_result_2.export_log(save_path_log_2, header=header)\n",
        "all_file_paths.append(save_path_log_2)\n",
        "\n",
        "# export text\n",
        "print(\"Exporting alignment results...\")\n",
        "save_path_list_text = []\n",
        "text_list, save_path_list_text_1 = alignment_result.export_as_text(save_dir=pwd)\n",
        "for file_path in save_path_list_text_1:\n",
        "    path = file_path.parent / (file_path.stem + \".alignment_with_prior.txt\")\n",
        "    os.replace(src=file_path, dst=path.as_posix())\n",
        "    save_path_list_text.append(path)\n",
        "text_list, save_path_list_text_2 = alignment_result_2.export_as_text(save_dir=pwd)\n",
        "for file_path in save_path_list_text_2:\n",
        "    path = file_path.parent / (file_path.stem + \".alignment_without_prior.txt\")\n",
        "    os.replace(src=file_path, dst=path.as_posix())\n",
        "    save_path_list_text.append(path)\n",
        "all_file_paths += save_path_list_text\n",
        "\n",
        "# print(\"Aligned Sequences\")\n",
        "# for text in text_list:\n",
        "#     print(text)\n",
        "\n",
        "# export gif\n",
        "if export_alignment_image:\n",
        "    print(\"Exporting alignment gifs...\")\n",
        "    refseq_name_list, text_list, highlight_pos_list = alignment_result.alignment_reuslt_list_2_text_list(linewidth=250)\n",
        "    save_path_list_gif = []\n",
        "    for refseq_name, text, highlight_pos in zip(refseq_name_list, text_list, highlight_pos_list):\n",
        "        # テキスト記入\n",
        "        splitted_text = text.split(\"\\n\")\n",
        "        ax0 = len(splitted_text)\n",
        "        ax1 = max([len(i) for i in splitted_text])\n",
        "        atcg_img = ATCG_5x5_img(ax0=ax0, ax1=ax1)\n",
        "        for ax0, t in enumerate(splitted_text):\n",
        "            atcg_img.write_letters(ax0, 0, t)\n",
        "        # ハイライト\n",
        "        for r, c in highlight_pos:\n",
        "            atcg_img.highlight_letter(r, c, (255, 100, 100))\n",
        "        # 保存(サイズでかいので分割)\n",
        "        save_path = (pwd / refseq_name).with_suffix(\".gif\")\n",
        "        save_paths = atcg_img.export_as_img(save_path=save_path, max_row_per_img=1000)\n",
        "        save_path_list_gif.extend(save_paths)\n",
        "    all_file_paths += save_path_list_gif\n",
        "\n",
        "# export score_summary\n",
        "print(\"Exporting summary...\")\n",
        "save_path_summary_score = pwd / \"summary_scores.txt\"\n",
        "score_summary = alignment_result.save_score_summary(save_path=save_path_summary_score)\n",
        "all_file_paths.append(save_path_summary_score)\n",
        "\n",
        "# print(\"Score Summary\")\n",
        "# print(score_summary)\n",
        "\n",
        "# export summary image\n",
        "print(\"Exporting summary svg images...\")\n",
        "save_path_summary_dictribution = pwd /\"summary_distribution.svg\"\n",
        "save_path_summary_scatter = pwd / \"summary_scatter.svg\"\n",
        "score_summary_df = pd.read_csv(save_path_summary_score, sep=\"\\t\")\n",
        "draw_distributions(score_summary_df, combined_fastq)\n",
        "plt.savefig(save_path_summary_dictribution)\n",
        "plt.close()\n",
        "draw_alignment_score_scatter(score_summary_df, score_threshold)\n",
        "plt.savefig(save_path_summary_scatter)\n",
        "plt.close()\n",
        "all_file_paths.extend([save_path_summary_dictribution, save_path_summary_scatter])\n",
        "\n",
        "# export consensus\n",
        "print(\"Exporting consensus fastq files...\")\n",
        "consensus_path_list = []\n",
        "consensus_path_list_1 = alignment_result.save_consensus(save_dir=pwd)\n",
        "for file_path in consensus_path_list_1:\n",
        "    path = file_path.parent / (file_path.stem + \".consensus_with_prior.fastq\")\n",
        "    os.replace(src=file_path, dst=(path).as_posix())\n",
        "    consensus_path_list.append(path)\n",
        "consensus_path_list_2 = alignment_result_2.save_consensus(save_dir=pwd)\n",
        "for file_path in consensus_path_list_2:\n",
        "    path = file_path.parent / (file_path.stem + \".consensus_without_prior.fastq\")\n",
        "    os.replace(src=file_path, dst=(path).as_posix())\n",
        "    consensus_path_list.append(path)\n",
        "\n",
        "all_file_paths += consensus_path_list\n",
        "\n",
        "# make new folder\n",
        "idx = 0\n",
        "results_dir = pwd / \"results\"\n",
        "while os.path.exists(results_dir.as_posix()):\n",
        "    idx += 1\n",
        "    results_dir = pwd / f\"results {idx}\"\n",
        "os.makedirs(results_dir)\n",
        "\n",
        "# move files\n",
        "for file_path in all_file_paths:\n",
        "    os.replace(src=file_path, dst=(results_dir / file_path.name).as_posix())\n",
        "\n",
        "# compress as zip\n",
        "os.chdir(results_dir)\n",
        "zip_path = results_dir.with_suffix(\".zip\")\n",
        "with zipfile.ZipFile(zip_path.as_posix(), 'w') as f:\n",
        "    for file_path in all_file_paths:\n",
        "        f.write(file_path.name)\n",
        "\n",
        "print(\"export: DONE\")\n",
        "\n",
        "if save_to_google_drive == True and drive:\n",
        "  uploaded = drive.CreateFile({'title': zip_path.name})\n",
        "  uploaded.SetContentFile(zip_path)\n",
        "  uploaded.Upload()\n",
        "  print(f\"Uploaded {zip_path} to Google Drive with ID {uploaded.get('id')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn1KKMsNmfxt",
        "outputId": "ad29a63b-6059-493c-cef0-b342ca2cc510"
      },
      "outputs": [],
      "source": [
        "#@title # 6. Visualize results\n",
        "\n",
        "target_file_path = \"_m243mod_Lyn11-FRB-dGFP-PLDs48(280-506)-P2A-PLDs48(1-279)-mCherry-iFKBP_pCAGGS.alignment_without_prior.txt\" #@param {type:\"string\"}\n",
        "target_position = 3164 #@param {type:\"number\"}\n",
        "display_range = 300 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "#@markdown ## 1-1. Upload files\n",
        "#@markdown `*.alignment_with_prior.txt` or `*.alignment_without_prior.txt`\n",
        "\n",
        "#@markdown ## 1-2. Select this cell and hit `Runtime` -> `Run after`\n",
        "\n",
        "import numpy as np\n",
        "import re\n",
        "from pathlib import Path\n",
        "pwd = Path('/content/sample_data/')\n",
        "\n",
        "class AlignmentViewer():\n",
        "    def __init__(self, file_path):\n",
        "        with open(file_path, \"r\") as f:\n",
        "            # ref\n",
        "            ref_line = f.readline()\n",
        "            m = re.match(r\"^(ref {1,}.+ {1,})([ATCGatcg-]+)$\", ref_line)\n",
        "            self.ref_label = m.group(1)\n",
        "            self.ref_seq = m.group(2)\n",
        "            len_label = len(self.ref_label)\n",
        "\n",
        "            # consensus\n",
        "            consensus_line_1 = f.readline()\n",
        "            assert consensus_line_1[:len_label] == \"consensus\" + \" \" * (len_label - 9)\n",
        "            self.consensus_seq = consensus_line_1[len_label:]\n",
        "            consensus_line_2 = f.readline()\n",
        "            assert consensus_line_2[:len_label] == \"consensus\" + \" \" * (len_label - 9)\n",
        "            self.consensus_q_scores = [ord(q) - 33 for q in consensus_line_2[len_label:]]\n",
        "\n",
        "            # query\n",
        "            self.query_list = []\n",
        "            i = 0\n",
        "            for line_0 in f:\n",
        "                line_0 =line_0.strip(\"\\n\")\n",
        "                line_1 = f.readline().strip(\"\\n\")\n",
        "                line_2 = f.readline().strip(\"\\n\")\n",
        "                self.query_list.append(Query(line_0, line_1, line_2))\n",
        "\n",
        "        # idx etc.\n",
        "        self.refseq_len = len(self.ref_seq) - self.ref_seq.count(\"-\")\n",
        "        i = 1\n",
        "        self.refseq_idx_list = []\n",
        "        for b in self.ref_seq:\n",
        "            if b != \"-\":\n",
        "                self.refseq_idx_list.append(i)\n",
        "                i += 1\n",
        "            else:\n",
        "                self.refseq_idx_list.append(-1)\n",
        "        assert max(self.refseq_idx_list) == self.refseq_len\n",
        "    def print(self, target_position, display_range):    # starts with 1\n",
        "        assert 0 < target_position <= self.refseq_len\n",
        "        beg = max(target_position - display_range, 1)\n",
        "        end = min(target_position + display_range, self.refseq_len)\n",
        "        b = self.refseq_idx_list.index(beg)\n",
        "        if end < self.refseq_len:  e = self.refseq_idx_list.index(end + 1)\n",
        "        else:                      e = len(self.ref_seq)\n",
        "        t = self.refseq_idx_list.index(target_position)\n",
        "        # print ref\n",
        "        printed_refseq = self.print_core(b, e, t, target_position)\n",
        "        # print query\n",
        "        for query in self.query_list:\n",
        "            query.print_core(b, e, t, printed_refseq)\n",
        "    def print_core(self, b, e, t, target_position):\n",
        "        # consensus q-scores\n",
        "        print(' ' * (len(self.ref_label) + 0 - len(\"consensus q-scores \")) + \n",
        "            \"consensus q-scores \" + \"\".join(map(lambda x: f\"{x:<3}\", self.consensus_q_scores[b:e:3]))\n",
        "        )\n",
        "        print(' ' * (len(self.ref_label) + 1) + \"\".join(map(lambda x: f\"{x:<3}\", self.consensus_q_scores[b+1:e:3])))\n",
        "        print(' ' * (len(self.ref_label) + 2) + \"\".join(map(lambda x: f\"{x:<3}\", self.consensus_q_scores[b+2:e:3])))\n",
        "        # pre\n",
        "        print(f\"\\033[1m{' ' * (len(self.ref_label) - len(str(target_position)) - 6 - 1)}(pos:{target_position}) {' ' * (t - b)}*{' ' * (e - t - 1)} Q-score\\033[0m\")\n",
        "        # ref\n",
        "        printed_refseq = self.ref_seq[b:e]\n",
        "        print(f\"\\033[1m{self.ref_label + self.ref_seq[b:t]}\\033[48;2;200;200;200m{self.ref_seq[t]}\\033[0m\\033[1m{self.ref_seq[t+1:e]}\\033[0m\")\n",
        "        # consensus\n",
        "        printed_consensus = \"\"\n",
        "        for i, j, idx in zip(self.consensus_seq[b:e], self.ref_seq[b:e], range(b, e)):\n",
        "            if i.upper() == j.upper():\n",
        "                printed_consensus += f\"\\033[1m{i}\\033[0m\"\n",
        "            else:\n",
        "                printed_consensus += f\"\\033[1m\\033[48;2;255;176;176m{i}\\033[0m\"\n",
        "            if idx == t:\n",
        "                if i.upper() == j.upper():\n",
        "                    bar_color = \"0;0;0\"\n",
        "                    bar_letter_color = \"255;255;255\"\n",
        "                else:\n",
        "                    bar_color = \"255;176;176\"\n",
        "                    bar_letter_color = \"0;0;0\"\n",
        "        # q_scores\n",
        "        printed_q_scores = f\"\\033[1m{self.consensus_q_scores[t]: >2}\"\n",
        "        # bar\n",
        "        printed_bar = f\"\\033[1m\\033[48;2;{bar_color}m\\033[38;2;{bar_letter_color}m{'*' * self.consensus_q_scores[t]}\\033[0m  \"\n",
        "        # print\n",
        "        print(f\"\\033[1mconsensus\\033[0m{' ' * (len(self.ref_label) - 9) + printed_consensus} {printed_q_scores} {printed_bar}\")\n",
        "        return printed_refseq\n",
        "\n",
        "class Query():\n",
        "    def __init__(self, line_0, line_1, line_2):\n",
        "        # sequence with insertion\n",
        "        m = re.match(r\"^([0-9]+ {1,}.+ {1,})([ATCGatcg-]+)$\", line_0)\n",
        "        self.query_label = m.group(1)\n",
        "        self.query_seq = m.group(2)\n",
        "        len_label = len(self.query_label)\n",
        "        # my_cigar_string\n",
        "        assert self.query_label == line_1[:len_label]\n",
        "        self.my_cigar_string = line_1[len_label:]\n",
        "        # q_score\n",
        "        assert self.query_label == line_2[:len_label]\n",
        "        self.q_scores = [ord(q) - 33 for q in line_2[len_label:]]\n",
        "    def print_core(self, b, e, t, printed_refseq):\n",
        "        # label, seq\n",
        "        printed_query_seq = \"\"\n",
        "        previous_L = \"\"\n",
        "        bar_color = None\n",
        "        for i, j, k, idx in zip(self.query_seq[b:e], self.my_cigar_string[b:e], printed_refseq, range(b, e)):\n",
        "            if (previous_L == \" \") & (i == \"-\"):\n",
        "                L = \" \"\n",
        "            elif j in \"HS\":\n",
        "                L = \" \"\n",
        "            elif i.upper() == k.upper():\n",
        "                L = i\n",
        "            else:\n",
        "                L = f\"\\033[48;2;255;176;176m{i}\\033[0m\"\n",
        "            if (idx == t) and (L != \" \"):\n",
        "                L = f\"\\033[1m{L}\\033[0m\"\n",
        "                if i.upper() == k.upper():\n",
        "                    bar_color = \"0;0;0\"\n",
        "                else:\n",
        "                    bar_color = \"255;176;176\"\n",
        "            printed_query_seq += L\n",
        "            previous_L = L\n",
        "        # q-scores\n",
        "        if (self.q_scores[t] == -1) or (bar_color is None):\n",
        "            q_score = \"  \"\n",
        "            bar = \"  \"\n",
        "        else:\n",
        "            q_score = f\"{self.q_scores[t]: >2}\"\n",
        "            bar = f\"\\033[48;2;{bar_color}m\\033[38;2;{bar_color}m{'*' * self.q_scores[t]}\\033[0m  \"\n",
        "        printed_q_scores = f\"{q_score}\"\n",
        "        # print\n",
        "        print(f\"{self.query_label}{printed_query_seq} {printed_q_scores} {bar}\")\n",
        "        return printed_query_seq\n",
        "\n",
        "file_path = pwd / target_file_path\n",
        "if file_path.exists():\n",
        "    alignment_viewer = AlignmentViewer(file_path)\n",
        "    alignment_viewer.print(target_position, display_range)\n",
        "else:\n",
        "    print(f\"file does not exist:\\n{file_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit ('env_RAPID')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "65fb75ef547f7f70fb8dbc6edf61adc9b4cedb2ccbdc90e1548a5e817107408e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "024ac7d11e9e4f1a9556f80496032998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eef62aa5a6d4ec0b3f43659125403e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M161_CRY2-mCherry-PLDs27-P2A-CIBN-CAAX_pcDNA3.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_ef911121b22d4cffb15d3fe8eac422ce",
            "style": "IPY_MODEL_c3fa16b75f204a63ad0f134f3ef2b0d4",
            "value": true
          }
        },
        "15f0c4bbf3904b8aa2ef8e060aa05935": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "2f175025fe254644b18a23dec4fea689": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "318776578cb448a2b5c101151734ae76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eed23829fc7a456287faec5b10a12212",
              "IPY_MODEL_d7be7716042443819bac1e4f59285daf",
              "IPY_MODEL_ebebfcf446e8496b8b42a96671f872f6",
              "IPY_MODEL_9e3a66f823f74afd86134878512f5f34",
              "IPY_MODEL_55b7831a74184e468f24326445969af4",
              "IPY_MODEL_57457741eb7a45b296b7b6abbed69a16",
              "IPY_MODEL_0eef62aa5a6d4ec0b3f43659125403e9",
              "IPY_MODEL_ea6a03d5a0254d2fa97f07f4df2c254a",
              "IPY_MODEL_a99c32318f404a8db6de10bac701b989",
              "IPY_MODEL_9869aa93aaf7422dac304d4b29b951d4"
            ],
            "layout": "IPY_MODEL_7ebf5aabec97438ea321eaadd47b8e25"
          }
        },
        "445a79881cda41018d41067aec740e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "4b60962f9b224da687e49c5cea7e138f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55b7831a74184e468f24326445969af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M38_mCherry-Spo20.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_b7e7c0fb2461485ba1bf0837a84d4407",
            "style": "IPY_MODEL_4b60962f9b224da687e49c5cea7e138f",
            "value": true
          }
        },
        "57457741eb7a45b296b7b6abbed69a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M43_iRFP713-PASS_vecCMV.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_cf5e783359944dddb8ebc5e445d08834",
            "style": "IPY_MODEL_a530f147945346bca51675b22f78b3eb",
            "value": true
          }
        },
        "667c569a0355492285af675400e9c10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67840ff1d93c4da1a7c577cc958a13a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7280ca6c2e804f39967ffac52e93ade5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7851a321173e404b89eb647f2da14df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ebf5aabec97438ea321eaadd47b8e25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fb13657e3194500be4456389f3a4a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9869aa93aaf7422dac304d4b29b951d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M32_pmNeonGreen-N1.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_2f175025fe254644b18a23dec4fea689",
            "style": "IPY_MODEL_67840ff1d93c4da1a7c577cc958a13a5",
            "value": true
          }
        },
        "9e3a66f823f74afd86134878512f5f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e7bf163628e45cc88a5e471f690c3e8",
            "placeholder": "​",
            "style": "IPY_MODEL_7851a321173e404b89eb647f2da14df2",
            "value": "# dna files"
          }
        },
        "9e7bf163628e45cc88a5e471f690c3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a530f147945346bca51675b22f78b3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a99c32318f404a8db6de10bac701b989": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M160_P18-CIBN-P2A-CRY2-mCherry-PLDs17_pcDNA3.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_445a79881cda41018d41067aec740e1f",
            "style": "IPY_MODEL_c58b7a3df57443f1bb41a77564bf037d",
            "value": true
          }
        },
        "b3a6e323e9d64815ac29813c176d017f": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7fb13657e3194500be4456389f3a4a2d",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "\n",
                  "1 fastq files selected\n",
                  "6 reference sequence files selected\n"
                ]
              }
            ]
          }
        },
        "b7e7c0fb2461485ba1bf0837a84d4407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "c3fa16b75f204a63ad0f134f3ef2b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c58b7a3df57443f1bb41a77564bf037d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf5e783359944dddb8ebc5e445d08834": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "d7be7716042443819bac1e4f59285daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Uematsu_n7x_1_MU-test1.fastq",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_15f0c4bbf3904b8aa2ef8e060aa05935",
            "style": "IPY_MODEL_667c569a0355492285af675400e9c10f",
            "value": true
          }
        },
        "dd421451047a4033bcda49b4708a6a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfaa5c7dc4794e53ba588eeee451a75f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea6a03d5a0254d2fa97f07f4df2c254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "M42_GFP-PASS_vecCMV.dna",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_f69ce397ca6845d299aeca9215f2e7b6",
            "style": "IPY_MODEL_dd421451047a4033bcda49b4708a6a78",
            "value": true
          }
        },
        "ebebfcf446e8496b8b42a96671f872f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfaa5c7dc4794e53ba588eeee451a75f",
            "placeholder": "​",
            "style": "IPY_MODEL_ff91334172304cd5bbe2c8d24b177685",
            "value": " "
          }
        },
        "eed23829fc7a456287faec5b10a12212": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7280ca6c2e804f39967ffac52e93ade5",
            "placeholder": "​",
            "style": "IPY_MODEL_024ac7d11e9e4f1a9556f80496032998",
            "value": "# fastq files"
          }
        },
        "ef911121b22d4cffb15d3fe8eac422ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "f69ce397ca6845d299aeca9215f2e7b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "80%"
          }
        },
        "ff91334172304cd5bbe2c8d24b177685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
